\hypertarget{2}{}

\chapter{Related Work}

\rhead{Related Work}
\lhead{Chapter 2}

\vspace{-1.6cm}

% Gray Line
\begingroup
\color{gray}
\par\noindent\rule{\textwidth}{0.4pt}
\endgroup

\noindent{This chapter presents the basic concepts and resources that support Relation Extraction (RE) deep learning techniques, namely, Natural Language Processing (NLP), text mining primary tasks, initial approaches for RE, distant supervision for RE, neural networks for RE, and evaluation measures.}

% ------------------------------> NATURAL LANGUAGE PROCESSING

\hypertarget{2.1}{\section{Natural Language Processing}}

Natural Language Processing (NLP) is an area in computer science that aims to derive meaning from unstructured or highly heterogeneous text written by humans. NLP covers several techniques that constitute pre-processing steps for the tasks described in Section \hyperlink{2.2}{2.2}. These NLP techniques have different goals and are often combined to obtain higher performance.

\begin{itemize}

\item{\textbf{Tokenization}: has the purpose of breaking the text into tokens to be processed individually or as a sequence. These tokens are usually words but can also be phrases, numbers and other types of elements. The most straightforward form of tokenization is breaking the input text by whitespaces or punctuation. However, with scientific biomedical literature, that is usually descriptive and formal, we have to account for complex entities like human phenotype terms (composed of multiple words),  genes (represented by symbols), and other types of structured entities. These entities tend to be morphological complex and need specialized tokenization pipelines. Some researchers use a compression algorithm \citep{DBLP:journals/corr/SennrichHB15}, byte pair encoding (BPE), to account for biomedical vocabulary variability. BPE represents open vocabularies through a fixed-size vocabulary of variable-length character sequences, making it suitable for neural networks models, for instance.} 

\item{\textbf{Stemming and Lemmatization}: aims at reducing the variability of natural language by normalizing a token to its base form (stem) \citep{Manning:2008:IIR:1394399}. It can also take into account the context of the token, along with vocabulary and morphological analysis to determine the canonical form of the word (lemma). The stem can correspond only to a fragment of a word, but the lemma is always a real word. For instance, the stem of the word \textit{having} is \textit{hav} and the lemma is \textit{have}.}

\item{\textbf{Part-of-Speech Tagging}: consists of assigning each word of a sentence to the category where it belongs taking into account their context (e.g., verb or preposition). Each word can belong to more than one category. This feature is useful to gain information on the role of a word in a given sentence.}

\item{\textbf{Parse Tree}: represents the syntactic structure of a sentence. There are two different types of parse trees: constituency-based parse trees and dependency-based parse trees. The main difference between the two is that the first distinguishes between the terminal and non-terminal nodes and the second does not (all nodes are terminal). In constituency-based parse trees, each node of the tree is either a \textit{root} node, a \textit{branch} node, or a \textit{leaf} node. For each given sentence there is only one \textit{root} node. The \textit{branch} node connects to two or more \textit{child} nodes, and the \textit{leaf} node is terminal. These leaves correspond to the lexical tokens \citep{AHO}. Dependency-based parse trees are usually simpler because they only identify the primary syntactic structure, leading to fewer nodes. Parse trees generate structures that are used as inputs for other algorithms and can be constructed based on supervised learning techniques.}

\end{itemize}

% ------------------------------> TEXT MINING

\hypertarget{2.2}{\section{Text Mining Primary Tasks}}

Text mining has become a widespread approach to identify and extract information from unstructured or highly heterogeneous text \citep{10.1371/journal.pcbi.1005962}. Text mining is used to extract facts and relationships in a structured form that can be used to annotate specialized databases and to transfer knowledge between domains \citep{FLEUREN201597}. We may consider text mining as a sub-field of data mining. Thus, data mining algorithms can be applied if we transform text to a proper data representation, namely numeric vectors. Even if in recent years text mining tools have evolved considerably in number and quality, there are still many challenges in applying text mining to scientific biomedical literature. The main challenges are the complexity and heterogeneity of the written resources, which make the retrieval of relevant information, i.e., relations between entities, a non a trivial task.
Text Mining tools can target different tasks together or separately. Some of the primary tasks are Named Entity Recognition (NER), Named-Entity Linking (NEL) and Relation Extraction (RE).

\begin{itemize}

\item{\textbf{Named Entity Recognition (NER)}: seeks to recognize and classify entities mentioned in the text by identifying the offset of its first and last character. The workflow of this task starts by spliting the text in tokens and then labeling them into categories (part-of-speech (POS) tagging). Some tools that perform NER, used in this dissertation, are the Identifying Human Phenotypes tool (IHP) \citep{IHP} and the Minimal Named-Entity Recognizer tool (MER) \citep{MER} tools. IHP is a NER tool, specifically created to recognize HPO entities in unstructured text. It uses Stanford CoreNLP \citep{Manning2014} for text processing and applies Conditional Random Fields trained with a rich feature set, combined with hand-crafted validation rules and a dictionary to improve the recognition of human phenotypes. MER is a NER tool which given any lexicon or ontology (e.g., an OWL file) and an input text is able to return a list of recognized entities, their location, and links to their classes.}

\item{\textbf{Named-Entity Linking (NEL)}: maps the recognized entities to entries in a given knowledge base. For instance, a gene can be written in multiple ways and mentioned by different names or acronyms in a text. NEL links all these different nomenclatures to one unique identifier. There are several organizations dedicated to providing identifiers, among them the National Center for Biotechnology Information (NCBI)\footnote{\url{https://www.ncbi.nlm.nih.gov/}} for genes, and the Human Phenotype Ontology (HPO) \citep{HPO} for phenotypic abnormalities encountered in human diseases. Also, the HUGO Gene Nomenclature Committee (HGNC) at the European Bioinformatics Institute\footnote{\url{http://www.genenames.org/}} is responsible for approving unique symbols and names for human loci, including protein-coding genes, ncRNA genes, and pseudogenes, with the goal of promoting clear scientific communication. All approved symbols are stored in the HGNC database.}

\item{\textbf{Relation Extraction (RE)}: identifies relations between entities (recognized manually or by NER) in a text. Tools mainly consider relations by the co-occurrence of the entities in the same sentence, but some progress is being made to extend this task to the full document (taking into account a global context) \citep{Singhal2016TextMG}.}

\end{itemize}

The workflow of a typical RE system is presented in Figure \ref{figure:2}.

\begin{figure}[hbt!]
\captionsetup{font=small}
\centering
\includegraphics[width=9cm]{images/figure_2.pdf}
\fontsize{9}{10.8}\caption[Relation Extraction Workflow]{Workflow of a simplified RE system. \textbf{DET} is a determinant, \textbf{NP} is a noun, \textbf{VP} is a verb, \textbf{AD} is an adjective, and \textbf{PP} is a preposition. Text obtained from \cite{Alves2018}.}
\label{figure:2}
\end{figure}

% ------------------------------> INITIAL APPROACHES FOR RELATION EXTRACTION

\section{Initial Approaches for Relation Extraction}

Through the years, several approaches have been proposed to extract relations from biomedical literature \citep{10.1371/journal.pone.0171929}. Most of these approaches work on a sentence level to perform RE, due to the inherent complexity of biomedical literature.

\begin{itemize}

\item{\textbf{Co-occurrence}: assumes that if two entities are mentioned in the same sentence (co-occur), it is likely that they are related. Usually, the application of this approach results in a higher recall (most of the entities co-occurring in a sentence participate in a relation), and lower precision. Some methods use frequency-based scoring schemes to eliminate relations identified by chance \citep{10.1093/bib/bbm045}. Nowadays, most applications use co-occurrence as a baseline against more complex approaches \citep{bunescu-etal-2006-integrating}.}

\item{\textbf{Pattern-based}: uses manually defined and automatically generated patterns to extract relations. \textbf{Manually defined patterns} require domain expertise knowledge about the type of biomedical entities, their interactions, and the text subject at hand. Initial systems made use of regular expressions to match word patterns that reflected a relation between two entities \citep{Zhou2008}, making use of a dictionary of words that express a relation, such as \textit{trigger} and \textit{stimulate}. Later systems introduce part-of-speech (POS) tagging, but this proven to be too naive, especially when applied to complex sentences, such as the ones that we typically find in biomedical literature \citep{10.1093/bioinformatics/bti493}. Opposite to the co-occurrence approaches, manually defined patterns frequently achieve high precision but tend to have poor recall. This approach does not generalize well, and therefore is difficult to apply to new unseen data. \textbf{Automatically generated patterns} encompass two main approaches, bootstrapping with \textit{seeds} \citep{10.1093/bioinformatics/btr155} and leveraging of the corpora \citep{Liu:2011:GES:2107691.2107717}. The bootstrapping method uses a small set of relations known as \textit{seeds} (e.g., gene-disease pairs). The first step is to identify the \textit{seeds} in the data set and map the relation pattern they describe. The second step is to try to apply the mapped patterns to the data set to identify new pairs of relations that follow the same construction. Finally, expanding the original set of relations by adding these new pairs. When repeating all previous steps, if no more pairs are found, the process ends. Some systems apply distant supervision techniques to keep track of the validity of the added patterns. Distant supervision uses existing knowledge base entries as gold standards to confirm or discard a relation. This method is susceptible to noisy patterns, as the original set of relations grows. On the other hand, the leveraging of the corpora method makes immediately use of the entire data set to generate the patterns.  This method requires a higher number of annotated relations and produces highly specific patterns, that are unable to match new unseen data. Automatically generated patterns can achieve a higher recall than manually defined patterns, but overall the noisy patterns continue damaging the precision. Nevertheless, there are a few efforts to reduce the number of noisy patterns \citep{Nguyen2010}.}

\item{\textbf{Rule-based}: also uses manually defined and automatically generated rules from the training data to extract relations. Depending on the systems, the differences between pattern-based and ruled-based approaches can be minor. Ruled-based approaches not only use patterns but also additional restraints to cover issues that are difficult to express by patterns, such as checking for the negation of the relations \citep{10.1093/bioinformatics/bti084}. Some ruled-based systems distance themselves from pattern-based approaches by replacing regular expressions with heuristic algorithms and sets of procedures \citep{Rinaldi:2007:MRP:1224550.1224593}. Similarly to pattern-based, ruled-based approaches tend to have poor recall, even though rules tend to be more flexible. The trade-off recall/precision can be improved using automatic methods for rule creation \citep{10.1136/amiajnl-2011-000776}.}

\item{\textbf{Machine Learning (ML)-based}: usually makes use of large annotated biomedical corpora (supervised learning) to perform RE. These corpora are pre-processed using NLP tools and then used to train classification models. Beyond Distant Supervision and Neural Networks, described in detail in Sections \hyperlink{2.4}{2.4} and \hyperlink{2.5}{2.5}, respectively, it is possible to categorize ML methods into two main approaches, Feature-based and Kernel-based. \textbf{Feature-based approaches} represent each instance (e.g., sentence) as a vector in an n-dimensional space. Support Vector Machines (SVM) classifiers tend to be used to solve problems of binary classification, and are considered \textit{black-boxs} because there is no interference of the user in the classification process. These classifiers can use different features that are meant to represent the data characteristics (e.g., shortest path, bag-of-words (BOW), and POS tagging) \citep{Kim2008DetectionOG}. \textbf{Kernel-based approaches} main idea is to quantify the similarity between the different instances in a data set by computing the similarities of their representations \citep{Giuliano06exploitingshallow}. Kernel-based approaches add the structural representation of instances (e.g., by using parse trees). These methods can use one kernel or a combination of kernels (e.g., graph, sub-tree (ST), and shallow linguistic (SL)).}

\end{itemize}

% ------------------------------> DISTANT SUPERVISION FOR RELATION EXTRACTION

\section{Distant Supervision for Relation Extraction}

Distant Supervision (or weak supervision) heuristically assigns labels to the data in the training corpus based on a provided knowledge base. This technique considers that a pair of entities in any sentence corresponding to a knowledge base entry is likely to describe a relation between those entities. For instance, in the sentence \textit{the \textbf{CRB1} gene is a key target in the fight against \textbf{blindness}}, the \textit{CRB1} and \textit{blindness} entities correspond to an entry in the gold standard human phenotype-gene relations knowledge base, provided by the HPO, and therefore we assume that these entities participate in a relation. This creates a large number of false positives, because not necessarily all sentences that mention an entity pair express the target relation \citep{jiang-etal-2018-revisiting}. Nevertheless, this allows us to use a training corpus of any size, an advantage that we do not have in supervised machine learning approaches, that require an annotated corpus. 

Distant supervision is not a viable RE system by its own, but the pseudo-relations inferred using this method can be used to train a classifier through machine learning algorithms \citep{10.1371/journal.pone.0171929}. 

% ----------------> MULTI-INSTANCE LEARNING

\hypertarget{2.4}{\subsection{Multi-instance Learning}}

\textbf{Multi-instance learning} \citep{Dietterich:1997:SMI:249678.249682} can solve some of the limitations of distant supervision. This supervised machine learning method uses labeled \textit{bags} instead of labeled instances. These \textit{bags} contain many instances and are suited for when there is a limited amount of knowledge of the labels. The simplest case of multi-instance learning is binary classification. In this case a \textit{bag} is labeled negative if all the instances in the \textit{bag} are negative and positive if at least one of the instances in the \textit{bag} is positive. Then, these labeled \textit{bags} are fed to a learning algorithm. The algorithm that is going to be used in this dissertation is the \textbf{sparse multi-instance learning (sMIL) algorithm} \citep{Bunescu:2007:MIL:1273496.1273510}. The instance-level ($x$) classifier $f(\overrightarrow{x};\theta)$, where $\theta$ corresponds to the parameters learned by the classifier, is learned by using a set of instances $I = I^+ \cup I^-$ that we can define as follows \citep{AMORES201381}:

\begin{equation} \label{eq:negativeinstances}
\small
\begin{gathered}
I^+ = \{\mu(X) : X \in B^+\} \\
I^- = \{\overrightarrow{x} : \overrightarrow{x} \in B^-\}
\end{gathered}
\end{equation}

where $I^+$ and $I^-$ are the sets of instances considered positive and negative, respectively. $\mu(X)$ is the average of instances inside $X$, and $B^+$ and $B^-$ are the sets of positive and negative \textit{bags}, respectively.

The idea of the sMIL algorithm is to learn a classifier with a relaxed constraint on the classification of the positive instances in $I^+$. The goal is to avoid forcing the classifier to provide a positive value for all the instances of a positive \textit{bag} but only to at least one of the instances. To achieve this, the sMIL algorithm applies two sets of constraints:

\begin{equation} \label{eq:firstset}
\small
f(\overrightarrow{x};\theta) \leq -1 + \xi_-, \quad \forall \overrightarrow{x} \in I^-
\end{equation}

Equation \ref{eq:firstset} forces the $f(\overrightarrow{x};\theta)$ function to provide a negative value when applied to negative instances, allowing for some degree of misclassification with the $\xi_-$ variable. 

\begin{equation} \label{eq:secondset}
\small
f(\mu(X);\theta) \geq \bigg(\frac{2}{\mid X \mid} -1\bigg) - \xi_+, \quad \forall X \in B^+
\end{equation}

Equation \ref{eq:secondset} provides a more relaxed condition for positive instances, depending on the size of the \textit{bag} $X$ from where $\mu(X)$ is extracted. If the \textit{bag} $X$ only contains one instance, we use the standard condition $f(\mu(X);\theta) \geq  1 - \xi_+$ (maintaining the slack variable, $\xi_+$). Else, if the \textit{bag} $X$ contains many instances, the threshold imposed on the classifier is gradually more and more relaxed. 

The sMIL algorithm assumes that the positive \textit{bags} are sparse. An abstract may mention each entity in the candidate pair multiple times, but due to the limitation of the number of words the relation is usually stated only once. Non-biomedical RE systems already applied similar techniques to extract Freebase relations from newspaper articles \citep{10.1007/978-3-642-15939-8_10}, and to reduce the number of incorrectly labeled relations (by distant supervision methods) \citep{min-etal-2013-distant}.

% ------------------------------> NEURAL NETWORKS FOR RELATION EXTRACTION

\hypertarget{2.5}{\section{Neural Networks for Relation Extraction}}

Artificial neural networks have multiple different architectures implementations and variants. They often use data representations as additional sources of information to perform text mining tasks, and can even use ontologies as external sources of information to enrich the model.

% ----------------> ARCHITECTURES

\subsection{Architectures}

\textbf{Artificial Neural Networks} are a parallel combination of small processing units (nodes) which can acquire knowledge from the environment through a learning process and store the knowledge in the connections between the nodes \citep{Haykin:1998:NNC:521706} (represented by direct graphs \citep{GURESEN2011426}) (Figure \ref{figure:3}). The process is inspired by the biological brain function, having each node corresponding to a \textit{neuron} and the connections between the nodes representing the \textit{synapses}.

\begin{figure}[hbt!]
\captionsetup{font=small}
\centering
\includegraphics[width=10cm]{images/figure_3.pdf}
\fontsize{9}{10.8}\caption[Artificial Neural Networks Architecture]{Architecture representation of an artificial neural networks model, where x\textsubscript{0-t} represents the inputs and h\textsubscript{0-t} the respective outputs, for each module from A to D.}
\label{figure:3}
\end{figure}

\textbf{Recurrent Neural Networks} (RNN) is a type of artificial neural network where the connections between the nodes are able to follow a temporal sequence. This means that RNN can use their internal state, or \textit{memory}, to process each input sequence (Figure \ref{figure:4}). Deep learning techniques, such as RNN, aim to train classification models based on word embeddings, part-of-speech (POS) tagging, and other features. RNN classifiers have multilayer architectures, where each layer learns a different representation of the input data. This characteristic makes RNN classifiers flexible to multiple text mining tasks, without requiring task-specific feature engineering.

\begin{figure}[hbt!]
\captionsetup{font=small}
\centering
\includegraphics[width=13cm]{images/figure_4.pdf}
\fontsize{9}{10.8}\caption[Recurrent Neural Networks Architecture]{Architecture representation of a recurrent neural networks model, where x\textsubscript{0-t} represents the inputs and h\textsubscript{0-t} the respective outputs, for the repeating module A.}
\label{figure:4}
\end{figure}

\textbf{Long Short-Term Memory} (LSTM) networks are an alternative to regular RNN \citep{Hochreiter:1997:LSM:1246443.1246450}.  LSTMs are a type of RNN that handles long dependencies (e.g., sentences), making this classifier more suitable for the biomedical domain, where sentences are usually long and descriptive (Figure \ref{figure:5}). In recent years, the use of LSTMs to perform Relation Extraction (RE) tasks has become widespread in various domains, such as semantic relations between nominals \citep{miwa-bansal-2016-end}. \textbf{Bidirectional LSTMs} use two LSTM layers, at each step, one that reads the sentence from right to left, and other that reads from left to right. The combined output of both layers produces a final score for each step. Bidirectional LSTMs have yield better results than traditional LSTMs when applied to the same data sets \citep{zhang-etal-2015-bidirectional}.

\begin{figure}[hbt!]
\captionsetup{font=small}
\centering
\includegraphics[width=10cm]{images/figure_5.pdf}
\fontsize{9}{10.8}\caption[Long Short-Term Memory Networks Architecture]{Architecture representation of a long-short-term memory networks model, where x\textsubscript{0-t} represents the inputs and h\textsubscript{0-t} the respective outputs, for the repeating module A, where each repeating module has four interacting layers (l\textsubscript{0-3}).}
\label{figure:5}
\end{figure}

% ----------------> DATA REPRESENTATIONS

\hypertarget{2.5.2}{\subsection{Data Representations}}

The combination of multiple and different language and entity related data representations is vital for the success of neural network models dedicated to RE tasks. Some of these features were already described in Section \hyperlink{2.1}{2.1}, such as POS tagging and parse trees. 

\textbf{Shortest Dependency Path} (SDP) is a feature that identifies the words between two entities mentioned in the text, concentrating the most relevant information while decreasing noise \citep{xu-etal-2015-classifying}. 

\textbf{Word Embeddings} are fixed-sized numerical vectors that aim to capture the syntactic and semantic word relationships. These word vectors models use multiple different pre-training sources, for instance, Word2Vec \citep{Mikolov:2013:DRW:2999792.2999959} uses English Wikipedia, and BERT \citep{BERT} uses both English Wikipedia and BooksCorpus. Early models, such as Word2Vec, learned one representation per word, but this proved to be problematic due to polysemous and homonymous words. Recently, most systems started to apply one embedding per word sense. One of the reasons why BERT outperforms previous methods is because it uses contextual models, meaning that it generates a unique representation for each word in a sentence. For instance, in the sentences fragments, \textit{they got \textbf{engaged}}, and \textit{students were very \textbf{engaged} in}, the word \textit{engaged} for non-contextual models would have the same meaning. BERT also outperforms other word vector models that take into account the sentence context, such as ELMo \citep{DBLP:journals/corr/abs-1802-05365} and ULMFit \citep{howard-ruder-2018-universal}, due to being an unsupervised and deeply bidirectional pre-trained language representation. 

\textbf{WordNet Hypernyms} are a feature that helps to hierarchize entities, structuring words similar to direct acyclic graphs \citep{WORDNET}. For example, \textit{vegetable} is a hypernym of \textit{tubers}, which in turn constitutes a hyponym of \textit{vegetable}. This feature is comparable to an ontology in the sense that a hierarchy relation is identified, but is missing the identification of the relations between the different terms. 

Using different features as information sources feeding individual channels leads to multichannel architecture models. Multichannel approaches were already proven to be effective in RE tasks \citep{xu-etal-2015-classifying}. 

Regarding biomedical RE, LSTMs were successful in identifying drug-drug interactions \citep{Wang2017}, gene-mutation relations \citep{song-etal-2018-n}, drug-mutation relations \citep{peng-etal-2017-cross}, among others. Some methods use domain-specific biomedical resources to train features for biomedical tasks. BioBERT \citep{BIOBERT} is a domain specific language representation model pre-trained on large-scale biomedical corpora, based on BERT \citep{BERT} architecture. BioBERT, using minimal task-specific architecture modifications, significantly outperforms previous biomedical state-of-the-art models in the text mining primary tasks of Named-Entity Recognition, Named-Entity Linking, and RE. The BR-LSTM \citep{Xu2018LeveragingBR} model uses a multichannel approach with pre-trained medical concept embeddings. Using the Unified Medical Language System (UMLS) concepts, BR-LSTM applies a medical concept embedding method developed by \cite{DeVine:2014:MSS:2661829.2661974}. BO-LSTM \citep{BOLSTM} uses the relations provided by domain-specific ontologies to aid the identification and classification of relations between biomedical entities in biomedical literature. 

% ----------------> ONTOLOGIES

\subsection{Ontologies}

An ontology is a structured way of providing a common vocabulary in which shared knowledge is represented \citep{Gruber}. Word embeddings can learn how to detect relations between entities but manifest difficulties in grasping the semantics of each entity and their specific domain. Domain-specific ontologies provide and formalize this knowledge. Biomedical ontologies are usually structured as a directed acyclic graph, where each node corresponds to an entity and the edges correspond to known relations between those entities. Thus, a structured representation of the semantics between entities and their relations, an ontology, allows us to use it as an added feature to a machine learning classifier. Some of the biomedical entities structured in publicly available ontologies are genes properties/attributes (Gene Ontology (GO)), phenotypes (Human Phenotype Ontology (HPO)), diseases (Disease Ontology (DO)), and chemicals (Chemical Entities of Biological Interest (ChEBI)). All of these entities participate in relations with different and same domain type entities. Hence, the information about each entity on a semantic level adds a new layer of knowledge to increase the performance of RE classifiers. For that end, this work uses the HPO and GO ontologies. The \textbf{HPO} is responsible for providing a standardized vocabulary of phenotypic abnormalities encountered in human diseases, using biomedical literature \citep{HPO}. The goal of this ontology is to facilitate medical documents readiness and exchange of medical information between medical professionals and researchers. The HPO entities are often long and descriptive, not following a specific nomenclature, making it hard to identify in unstructured text. The HPO currently contains over 13.000 terms and over 156.000 annotations to hereditary diseases. The \textbf{GO} defines a universe of concepts regarding gene functions (GO terms) and their relations \citep{GO}. The GO encompass three categories (sub-ontologies): \textit{molecular function} (11.110 terms), \textit{cellular component} (4.206 terms), and \textit{biological process} (29.687 terms), and three types of relations, \textit{is a}, \textit{part of} and \textit{regulates}. As in HPO terms, GO terms are usually long and descriptive. The primary goal of this ontology is to create a dynamic controlled vocabulary that can be applied to all eukaryotes, allowing for inferences regarding gene function by connecting different organisms.

Non-biomedical models using ontologies as an added source of information to neural networks is becoming widespread for several tasks. \cite{10.1007/978-3-319-50496-4_19} propose using word sense definitions, provided by the WordNet ontology, to learn one embedding per word sense for word sense disambiguation tasks. \cite{10.1007/978-3-319-63579-8_15} focus their work on semantic relations between ontologies and documents, using the DBpedia ontology. Some researchers explored graph embedding techniques \citep{GOYAL201878} that convert relations to a low dimensional space which represents the structure and properties of the graph. Other researchers have combined different sources of information, including ontological information, to do multi-label classification \citep{Kong:2013:MCM:2487575.2487577} and used ontology concepts to represent word tokens \citep{dasigi-etal-2017-ontology}.

However, few authors have used biomedical ontologies to perform RE. Textpresso \citep{10.1371/journal.pbio.0020309} is a text-mining system that works as a search engine of individual sentences, acquired from the full text of scientific articles, and articles. It integrates biomedical ontological information (e.g., of genes, phenotypes, and proteins) allowing for article and sentence search a query by term. The integration of the ontological information allows for semantic queries. This system helps database curation by automatically extracting biomedical relations. The IICE \citep{Lamurias2014IdentifyingIB} system uses kernel-based support vector machines along with an ensemble classifier to identify and classify drug-drug interactions, linking each chemical compound to the ChEBI ontology. \cite{Tripodi2017KnowledgeBaseEnrichedRE} system focus on drug-gene/protein interaction discovery to aid database curation, making use of ChEBI and GO ontologies. BO-LSTM \citep{BOLSTM} is the only model until now that incorporates ancestry information from biomedical ontologies with deep learning to extract relations from the text, specifically drug-drug interactions and gene-phenotype relations. 

% ------------------------------> EVALUATION MEASURES

\hypertarget{2.4}{\section{Evaluation Measures}}

The evaluation of machine learning systems is done by applying the trained models to a gold standard test-set, manually curated or annotated by domain experts and unseen by the system. For a Relation Extraction (RE) task, the gold standard test-set should correspond to the list of pairs of entities (e.g., phenotype-gene or gene-disease pairs) that co-occur in the same sentences and their relation (\textit{Known} or \textit{Unknown}).
To any given information extraction system it is necessary to define what constitutes a positive and negative result. In RE tasks the types of results possible are shown in Table \ref{table:evaluation}.

\begin{table}[!ht]
\renewcommand\arraystretch{1.2}
\small
\captionsetup{font=small}
\caption[Types of Results Obtained with an Information Extraction System for a RE Task]{Types of results obtained with an information extraction system for a RE task.}
\centering
\taburulecolor{black}
\begin{tabular}{ |c|c|c| }
\hline
\textbf{Annotator (Gold Standard)} & \textbf{System} & \textbf{Classification}\\
\hline\hline
\multirow{2}{*}{Relation} & Relation & True Positive (TP) \\
\cline{2-3}
 & No Relation & False Negative (FN) \\ 
\hline
\multirow{2}{*}{No Relation} & Relation & False Positive (FP) \\
\cline{2-3}
 & No Relation & True Negative (TN) \\
 \hline
\end{tabular}
\label{table:evaluation}
\end{table}

The primary goal of a given information retrieval system is to maximize the number of TP and TN. To compare results obtained with different data sets or different tools we have three distinct evaluation metrics: recall, precision and F-measure. Precision represents how often the results are correct, recall the number of correct results identified and F-measure is a combination of both metrics to express overall performance, being the harmonic mean of precision and recall:

\begin{equation}
\small
Recall = \frac{TP}{TP + FN}
\qquad
Precision = \frac{TP}{TP + FP}
\qquad
F-measure = \frac{2\times Precision\times Recall}{Precision + Recall}
\label{equation:evaluation}
\end{equation}

The performance of the most recent systems dedicated to biomedical RE, described in Section \hyperlink{2.5.2}{2.5.2}, is shown in Table \ref{table:evaluation_soa}. These systems are not comparable, since each system is focused on the relations between different biomedical entities, and even addresses more than binary relations, such as the Graph LSTM (GOLD) system. 

\begin{table}[!ht]
\renewcommand\arraystretch{1.2}
\small
\captionsetup{font=small}
\caption[Biomedical RE Systems Performance]{Biomedical RE systems current performance.}
\centering
\taburulecolor{black}
\begin{tabular}{ |c|c|c|c| }
\hline
\textbf{System} & \textbf{Precision} & \textbf{Recall} & \textbf{F-Measure}\\
\hline\hline
DLSTM \citep{Wang2017} & 0.7253 & 0.7149 & 0.7200 \\
\hline
Graph LSTM (GOLD) \citep{song-etal-2018-n} & 0.4330 & 0.3050 & 0.3580 \\ 
\hline
BioBERT \citep{BIOBERT} & 0.8582 & 0.8640 & 0.8604 \\
\hline
BR-LSTM \citep{Xu2018LeveragingBR} & 0.7152 & 0.7079 & 0.7115 \\
\hline
BO-LSTM \citep{BOLSTM} & 0.6572 & 0.8184 & 0.7290 \\
\hline
\end{tabular}
\label{table:evaluation_soa}
\end{table}

For RE tasks a human acceptable performance is usually around 85/90\% in F-measure \citep{Aroyo2015TruthIA}. To facilitate the creation of gold standards we should strive for semi-automation, that is, employ automatic methods for corpora annotation (creating silver standard corpora), and then correct those annotations using domain-specific curators. 

The inter-curator agreement metric, that is going to be used in this work to evaluate the quality of the curation of the silver standard corpus annotations, is calculated through the Cohen's Kappa Coefficient (κ) \citep{doi:10.1177/001316446002000104}:

\begin{equation}
\small
\kappa = \frac{P(A) - P(E)}{1 - P(E)}
\label{equation:agreement}
\end{equation}

where \textit{P}(\textit{A}) corresponds to the percentage of agreement and \textit{P}(\textit{E}) the percentage that was expected inter-curators or inter-annotators to agree by chance.

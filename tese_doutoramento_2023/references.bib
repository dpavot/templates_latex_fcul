% CHAPTER 1

@inproceedings{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={Advances in neural information processing systems},
  publisher = {Curran Associates, Inc.},
  address = {Online},
  pages={1877--1901},
  year={2020}
}

@article{sousa2023k,
  title={K-{RET}: knowledgeable biomedical relation extraction system},
  author={Sousa, Diana F and Couto, Francisco M},
  journal={Bioinformatics},
  volume={39},
  number={4},
  pages={1--8},
  year={2023},
  publisher={Oxford University Press}
}

@article{lamurias2020generating,
  title={Generating biomedical question answering corpora from {Q\&A} forums},
  author={Lamurias, Andre and Sousa, Diana and Couto, Francisco M},
  journal={IEEE Access},
  volume={8},
  pages={161042--161051},
  year={2020},
  publisher={IEEE}
}

@article{barros2021covid,
  title={{COVID}-19 recommender system based on an annotated multilingual corpus},
  author={Barros, M{\'a}rcia and Ruas, Pedro and Sousa, Diana and Bangash, Ali Haider and Couto, Francisco M},
  journal={Genomics \& Informatics},
  volume={19},
  number={3},
  year={2021},
  pages={1--7},
  publisher={Korea Genome Organization}
}

@inproceedings{barros2020covid,
    title = "{COVID}-19: A Semantic-Based Pipeline for Recommending Biomedical Entities",
    author = "Barros, Marcia  and
      Lamurias, Andre  and
      Sousa, Diana  and
      Ruas, Pedro  and
      Couto, Francisco M.",
    booktitle = "Proceedings of the 1st Workshop on {NLP} for {COVID}-19 (Part 2) at {EMNLP} 2020",
    month = dec,
    year = "2020",
    address = "Online",
    pages={1--9},
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.nlpcovid19-2.20",
    doi = "10.18653/v1/2020.nlpcovid19-2.20",
    abstract = "With the increasing number of publications about COVID-19, it is a challenge to extract personalized knowledge suitable for each researcher. This work aims to build a new semantic-based pipeline for recommending biomedical entities to scientific researchers. To this end, we developed a pipeline that creates an implicit feedback matrix based on Named Entity Recognition (NER) on a corpus of documents, using multidisciplinary ontologies for recognizing and linking the entities. Our hypothesis is that by using ontologies from different fields in the NER phase, we can improve the results for state-of-the-art collaborative-filtering recommender systems applied to the dataset created. The tests performed using the COVID-19 Open Research Dataset (CORD-19) dataset show that when using four ontologies, the results for precision@k, for example, reach the 80{\%}, whereas when using only one ontology, the results for precision@k drops to 20{\%}, for the same users. Furthermore, the use of multi-fields entities may help in the discovery of new items, even if the researchers do not have items from that field in their set of preferences.",
}

@inproceedings{sousalasigebiotm,
  title={lasige{B}io{TM} at {B}io{C}reative {VII} Track 1: Text mining drug and chemical-protein interactions using biomedical ontologies},
  author={Sousa, Diana and Cassanheira, Rodrigo and Couto, Francisco M},
  booktitle={Proceedings of the BioCreative VII Challenge Evaluation Workshop},
  pages={1--4},
  address={Online},
  publisher={Association for
Computational Linguistics},
  year={2021}
}

@inproceedings{sousa2021deep,
  title={Deep Learning System for Biomedical Relation Extraction Combining External Sources of Knowledge},
  author={Sousa, Diana},
  booktitle={Advances in Information Retrieval: 43rd European Conference on IR Research},
  pages={688--693},
  year={2021},
  address={Berlin, Heidelberg},
  organization={Springer}
}

% CHAPTER 2

@article{10.1093/database/bax064,
    author = {Campos, Luís and Pedro, Vasco and Couto, Francisco},
    title = "{Impact of translation on named-entity recognition in radiology texts}",
    journal = {Database},
    volume = {2017},
    pages = {1--9},
    year = {2017},
    month = {08},
    abstract = "{Radiology reports describe the results of radiography procedures and have the potential of being a useful source of information which can bring benefits to health care systems around the world. One way to automatically extract information from the reports is by using Text Mining tools. The problem is that these tools are mostly developed for English and reports are usually written in the native language of the radiologist, which is not necessarily English. This creates an obstacle to the sharing of Radiology information between different communities. This work explores the solution of translating the reports to English before applying the Text Mining tools, probing the question of what translation approach should be used. We created MRRAD (Multilingual Radiology Research Articles Dataset), a parallel corpus of Portuguese research articles related to Radiology and a number of alternative translations (human, automatic and semi-automatic) to English. This is a novel corpus which can be used to move forward the research on this topic. Using MRRAD we studied which kind of automatic or semi-automatic translation approach is more effective on the Named-entity recognition task of finding RadLex terms in the English version of the articles. Considering the terms extracted from human translations as our gold standard, we calculated how similar to this standard were the terms extracted using other translations. We found that a completely automatic translation approach using Google leads to F-scores (between 0.861 and 0.868, depending on the extraction approach) similar to the ones obtained through a more expensive semi-automatic translation approach using Unbabel (between 0.862 and 0.870). To better understand the results we also performed a qualitative analysis of the type of errors found in the automatic and semi-automatic translations.Database URL:https://github.com/lasigeBioTM/MRRAD}",
    issn = {1758-0463},
    doi = {10.1093/database/bax064},
    url = {https://doi.org/10.1093/database/bax064},
    eprint = {https://academic.oup.com/database/article-pdf/doi/10.1093/database/bax064/22892754/bax064.pdf},
}

@article{luo2022biored,
  title={Bio{RED}: a rich biomedical relation extraction dataset},
  author={Luo, Ling and Lai, Po-Ting and Wei, Chih-Hsuan and Arighi, Cecilia N and Lu, Zhiyong},
  journal={Briefings in Bioinformatics},
  volume={23},
  number={5},
  pages={1--12},
  year={2022},
  publisher={Oxford University Press}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  year={2018},
  pages={1--12},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
} 

@article{blei2012probabilistic,
  title={Probabilistic topic models},
  author={Blei, David M},
  journal={Communications of the ACM},
  volume={55},
  number={4},
  pages={77--84},
  year={2012},
  publisher={ACM}
}

@InProceedings{buchanan2007investigating,
author="Buchanan, George
and Loizides, Fernando",
title="Investigating Document Triage on Paper and Electronic Media",
booktitle="Research and Advanced Technology for Digital Libraries",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="416--427",
abstract="Document triage is the critical point in the information seeking process when the user first decides the relevance of a document to their information need. This complex process is not yet well understood, and subsequently we have undertaken a comparison of this task in both electronic and paper media. The results reveal that in each medium human judgement is influenced by different factors, and confirm some unproven hypotheses. How users claim they perform triage, and what they actually do, are often not the same.",
isbn="978-3-540-74851-9"
}

@article{nadeau2007survey,
  title={A survey of named entity recognition and classification},
  author={Nadeau, David and Sekine, Satoshi},
  journal={Lingvisticae Investigationes},
  volume={30},
  number={1},
  pages={3--26},
  year={2007},
  publisher={John Benjamins publishing company}
}

@inproceedings{bunescu2006using,
    title = "Using Encyclopedic Knowledge for Named entity Disambiguation",
    author = "Bunescu, Razvan  and
      Pa{\c{s}}ca, Marius",
    booktitle = "11th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = apr,
    year = "2006",
    address = "Trento, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/E06-1002",
    pages = "9--16",
}

@article{Ananiadou2010,
author = {Ananiadou, Sophia and Pyysalo, Sampo and Tsujii, Jun'ichi and Kell, Douglas B.},
doi = {10.1016/j.tibtech.2010.04.005},
journal = {Trends in Biotechnology},
number = {7},
pages = {381--390},
pmid = {20570001},
title = {{Event extraction for systems biology by text mining the literature}},
volume = {28},
year = {2010}
}

@article{CALIJORNESOARES2020635,
title = {A literature review on question answering techniques, paradigms and systems},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {32},
number = {6},
pages = {635--646},
year = {2020},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2018.08.005},
author = {Marco Antonio {Calijorne Soares} and Fernando Silva Parreiras},
keywords = {Question answering systems, Natural language processing, Information retrieval},
abstract = {Background
Question Answering (QA) systems enable users to retrieve exact answers for questions posed in natural language.
Objective
This study aims at identifying QA techniques, tools and systems, as well as the metrics and indicators used to measure these approaches for QA systems and also to determine how the relationship between Question Answering and natural language processing is built.
Method
The method adopted was a Systematic Literature Review of studies published from 2000 to 2017.
Results
130 out of 1842 papers have been identified as describing a QA approach developed and evaluated with different techniques.
Conclusion
Question Answering researchers have concentrated their efforts in natural language processing, knowledge base and information retrieval paradigms. Most of the researches focused on open domain. Regarding the metrics used to evaluate the approaches, Precision and Recall are the most addressed.}
}

@article{tsuruoka2008normalizing,
  title={Normalizing biomedical terms by minimizing ambiguity and variability},
  author={Tsuruoka, Yoshimasa and McNaught, John and Ananiadou, Sophia},
  journal={BMC Bioinformatics},
  volume={9},
  number={3},
  pages={1--10},
  year={2008},
  publisher={BioMed Central}
}

@inproceedings{hearst1999untangling,
  title={Untangling text data mining},
  author={Hearst, Marti A},
  booktitle={Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics},
  pages={3--10},
  year={1999},
  address={College Park, Maryland, USA},
  organization={Association for Computational Linguistics}
}

@article{notaro2017prediction,
  title={Prediction of Human Phenotype Ontology terms by means of hierarchical ensemble methods},
  author={Notaro, Marco and Schubach, Max and Robinson, Peter N and Valentini, Giorgio},
  journal={BMC bioinformatics},
  volume={18},
  number={1},
  pages={449},
  year={2017},
  publisher={BioMed Central}
}

@article{li2017neural,
  title={A neural joint model for entity and relation extraction from biomedical text},
  author={Li, Fei and Zhang, Meishan and Fu, Guohong and Ji, Donghong},
  journal={BMC Bioinformatics},
  volume={18},
  number={1},
  pages={1--11},
  year={2017},
  publisher={BioMed Central}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{jiang2016relation,
    title = "Relation Extraction with Multi-instance Multi-label Convolutional Neural Networks",
    author = "Jiang, Xiaotian  and
      Wang, Quan  and
      Li, Peng  and
      Wang, Bin",
    booktitle = "Proceedings of {COLING} 2016, the 26th International Conference on Computational Linguistics: Technical Papers",
    month = dec,
    year = "2016",
    address = "Osaka, Japan",
    publisher = "The COLING 2016 Organizing Committee",
    url = "https://aclanthology.org/C16-1139",
    pages = "1471--1480",
    abstract = "Distant supervision is an efficient approach that automatically generates labeled data for relation extraction (RE). Traditional distantly supervised RE systems rely heavily on handcrafted features, and hence suffer from error propagation. Recently, a neural network architecture has been proposed to automatically extract features for relation classification. However, this approach follows the traditional expressed-at-least-once assumption, and fails to make full use of information across different sentences. Moreover, it ignores the fact that there can be multiple relations holding between the same entity pair. In this paper, we propose a multi-instance multi-label convolutional neural network for distantly supervised RE. It first relaxes the expressed-at-least-once assumption, and employs cross-sentence max-pooling so as to enable information sharing across different sentences. Then it handles overlapping relations by multi-label learning with a neural network classifier. Experimental results show that our approach performs significantly and consistently better than state-of-the-art methods.",
}

@inproceedings{lin2016neural,
  title={Neural relation extraction with selective attention over instances},
  author={Lin, Yankai and Shen, Shiqi and Liu, Zhiyuan and Luan, Huanbo and Sun, Maosong},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2124--2133},
  address={Berlin, Germany},
  publisher={Association for Computational Linguistics},
  year={2016}
}

@inproceedings{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  booktitle={Advances in neural information processing systems},
  pages={3111--3119},
  address={Red Hook, NY, USA},
  publisher={Curran Associates, Inc.},
  year={2013}
}

@article{kumar2017survey,
  title={A survey of deep learning methods for relation extraction},
  author={Kumar, Shantanu},
  journal={arXiv preprint arXiv:1705.03645},
  pages={1--8},
  year={2017}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  publisher={Curran Associates, Inc.},
  address={Long Beach, CA, USA},
  year={2017}
}


@article{ashburner2000gene,
  title={Gene {O}ntology: tool for the unification of biology},
  author={Ashburner, Michael and Ball, Catherine A and Blake, Judith A and Botstein, David and Butler, Heather and Cherry, J Michael and Davis, Allan P and Dolinski, Kara and Dwight, Selina S and Eppig, Janan T and others},
  journal={Nature Genetics},
  volume={25},
  number={1},
  pages={25--29},
  year={2000},
  publisher={Nature Publishing Group}
}

@article{robinson2010human,
  title={The human phenotype ontology},
  author={Robinson, Peter N and Mundlos, S},
  journal={Clinical Genetics},
  volume={77},
  number={6},
  pages={525--534},
  year={2010},
  publisher={Wiley Online Library}
}

@article{lamurias2019bo,
  title={{BO-LSTM}: classifying relations via long short-term memory networks along biomedical ontologies},
  author={Lamurias, Andre and Sousa, Diana and Clarke, Luka A and Couto, Francisco M},
  journal={BMC Bioinformatics},
  volume={20},
  number={1},
  pages={1--12},
  year={2019},
  publisher={BioMed Central}
}

@inproceedings{sousa2020biont,
  title={Bi{O}nt: deep learning using multiple biomedical ontologies for relation extraction},
  author={Sousa, Diana and Couto, Francisco M},
  booktitle={Advances in Information Retrieval: 42nd European Conference on IR Research},
  address={Lisbon, Portugal},
  pages={367--374},
  year={2020},
  organization={Springer}
}

@inproceedings{sennrich2015neural,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and
      Haddow, Barry  and
      Birch, Alexandra",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1162",
    doi = "10.18653/v1/P16-1162",
    pages = "1715--1725",
}
@book{manning2008introduction,
  title={Introduction to information retrieval},
  author={Manning, Christopher D and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  year={2008},
  publisher={Cambridge University Press}
}

@book{aho1986compilers,
 author = {Aho, Alfred V. and Sethi, Ravi and Ullman, Jeffrey D.},
 title = {Compilers: Principles, techniques, \& tools},
 year = {1986},
 publisher = {Addison-Wesley},
}

@article{westergaard2018comprehensive,
  title={A comprehensive and quantitative comparison of text-mining in 15 million full-text articles versus their corresponding abstracts},
  author={Westergaard, David and St{\ae}rfeldt, Hans-Henrik and T{\o}nsberg, Christian and Jensen, Lars Juhl and Brunak, S{\o}ren},
  journal={PLoS Computational Biology},
  volume={14},
  number={2},
  pages={1--16},
  year={2018},
  publisher={Public Library of Science}
}

@article{fleuren2015application,
  title={Application of text mining in the biomedical domain},
  author={Fleuren, Wilco WM and Alkema, Wynand},
  journal={Methods},
  volume={74},
  pages={97--106},
  year={2015},
  publisher={Elsevier}
}

@article{singhal2016text,
  title={Text mining genotype-phenotype relationships from biomedical literature for database curation and precision medicine},
  author={Singhal, Ayush and Simmons, Michael and Lu, Zhiyong},
  journal={PLoS Computational Biology},
  volume={12},
  number={11},
  year={2016},
  pages={1--19},
  publisher={Public Library of Science}
}

@article{lamurias2017extracting,
  title={Extracting microRNA-gene relations from biomedical literature using distant supervision},
  author={Lamurias, Andre and Clarke, Luka A and Couto, Francisco M},
  journal={PloS One},
  volume={12},
  number={3},
  year={2017},
  pages={1--20},
  publisher={Public Library of Science}
}

@inproceedings{zhang2017review,
  title={A review on entity relation extraction},
  author={Zhang, Qianqian and Chen, Mengdong and Liu, Lianzhong},
  booktitle={2017 Second International Conference on Mechanical, Control and Computer Engineering},
  pages={178--183},
  year={2017},
  address={Harbin, China},
  organization={IEEE}
}

@article{zweigenbaum2007frontiers,
  title={Frontiers of biomedical text mining: current progress},
  author={Zweigenbaum, Pierre and Demner-Fushman, Dina and Yu, Hong and Cohen, Kevin B},
  journal={Briefings in Bioinformatics},
  volume={8},
  number={5},
  pages={358--375},
  year={2007},
  publisher={Oxford University Press}
}

@inproceedings{bunescu2006integrating,
  title={Integrating co-occurrence statistics with information extraction for robust retrieval of protein interactions from Medline},
  author={Bunescu, Razvan and Mooney, Raymond and Ramani, Arun and Marcotte, Edward},
  booktitle={Proceedings of the HLT-NAACL BioNLP Workshop on Linking Natural Language and Biology},
  pages={49--56},
  address={New York, NY, USA},
  year={2006},
  organization={Association for Computational Linguistics}
}

@book{smolinski2009computational,
  title={Computational Intelligence in Biomedicine and Bioinformatics: Current trends and applications},
  author={Smolinski, Tomasz G and Milanova, Mariofanna G and Hassanien, Aboul-Ella},
  year={2009},
  publisher={Springer}
}

@article{hao2005discovering,
  title={Discovering patterns to extract protein--protein interactions from the literature: Part {II}},
  author={Hao, Yu and Zhu, Xiaoyan and Huang, Minlie and Li, Ming},
  journal={Bioinformatics},
  volume={21},
  number={15},
  pages={3294--3300},
  year={2005},
  publisher={Oxford University Press}
}

@article{wang2011inference,
  title={Inference of transcriptional regulatory network by bootstrapping patterns},
  author={Wang, Hei-Chia and Chen, Yi-HSiu and Kao, Hung-Yu and Tsai, Shaw-Jenq},
  journal={Bioinformatics},
  volume={27},
  number={10},
  pages={1422--1428},
  year={2011},
  publisher={Oxford University Press}
}

@inproceedings{liu2011graphs,
  title={From graphs to events: A subgraph matching approach for information extraction from biomedical text},
  author={Liu, Haibin and Komandur, Ravikumar and Verspoor, Karin},
  booktitle={Proceedings of the BioNLP Shared Task 2011 Workshop},
  pages={164--172},
  year={2011},
  address={Portland, Oregon, USA},
  organization={Association for Computational Linguistics}
}

@article{nguyen2010simple,
  title={Simple tricks for improving pattern-based information extraction from the biomedical literature},
  author={Nguyen, Quang Long and Tikk, Domonkos and Leser, Ulf},
  journal={Journal of Biomedical Semantics},
  volume={1},
  number={1},
  pages={1--17},
  year={2010},
  publisher={Springer}
}

@article{koike2005automatic,
  title={Automatic extraction of gene/protein biological functions from biomedical text},
  author={Koike, Asako and Niwa, Yoshiki and Takagi, Toshihisa},
  journal={Bioinformatics},
  volume={21},
  number={7},
  pages={1227--1236},
  year={2005},
  publisher={Oxford University Press}
}

@article{xu2012feature,
  title={Feature engineering combined with machine learning and rule-based methods for structured information extraction from narrative clinical discharge summaries},
  author={Xu, Yan and Hong, Kai and Tsujii, Junichi and Chang, Eric I-Chao},
  journal={Journal of the American Medical Informatics Association},
  volume={19},
  number={5},
  pages={824--832},
  year={2012},
  publisher={BMJ Group BMA House, Tavistock Square, London, WC1H 9JR}
}

@article{kim2008detection,
  title={Detection of gene interactions based on syntactic relations},
  author={Kim, Mi-Young},
  journal={Journal of Biomedicine and Biotechnology},
  volume={2008},
  year={2008},
  pages={1--9},
  publisher={Hindawi Publishing Corporation}
}

@inproceedings{giuliano2006exploiting,
  title={Exploiting shallow linguistic information for relation extraction from biomedical literature},
  author={Giuliano, Claudio and Lavelli, Alberto and Romano, Lorenza},
  booktitle={11th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={401--408},
  publisher={Association for Computational Linguistics},
  address={Trento, Italy},
  year={2006}
}

@inproceedings{hoffmann2011knowledge,
  title={Knowledge-based weak supervision for information extraction of overlapping relations},
  author={Hoffmann, Raphael and Zhang, Congle and Ling, Xiao and Zettlemoyer, Luke and Weld, Daniel S},
  booktitle={Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1},
  pages={541--550},
  address={Portland, Oregon, USA},
  year={2011},
  organization={Association for Computational Linguistics}
}

@inproceedings{augenstein2015extracting,
    title = "Extracting Relations between Non-Standard Entities using Distant Supervision and Imitation Learning",
    author = "Augenstein, Isabelle  and
      Vlachos, Andreas  and
      Maynard, Diana",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1086",
    doi = "10.18653/v1/D15-1086",
    pages = "747--757",
}

@inproceedings{hasegawa2004discovering,
  title={Discovering relations among named entities from large corpora},
  author={Hasegawa, Takaaki and Sekine, Satoshi and Grishman, Ralph},
  booktitle={Proceedings of the 42nd annual meeting on association for computational linguistics},
  pages={415--422},
  year={2004},
  address={Barcelona, Spain},
  organization={Association for Computational Linguistics}
}

@inproceedings{shinyama2006preemptive,
  title={Preemptive information extraction using unrestricted relation discovery},
  author={Shinyama, Yusuke and Sekine, Satoshi},
  booktitle={Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics},
  pages={304--311},
  year={2006},
  address={Seattle, USA}, 
  organization={Association for Computational Linguistics}
}

@article{quan2014unsupervised,
  title={An unsupervised text mining method for relation extraction from biomedical literature},
  author={Quan, Changqin and Wang, Meng and Ren, Fuji},
  journal={PloS One},
  volume={9},
  number={7},
  pages={1--8},
  year={2014},
  publisher={Public Library of Science}
}

@book{haykin1994neural,
  title={Neural networks: a comprehensive foundation},
  author={Haykin, Simon},
  year={1994},
  publisher={Prentice Hall PTR}
}

@article{guresen2011definition,
  title={Definition of artificial neural networks with comparison to other networks},
  author={Guresen, Erkam and Kayakutlu, Gulgun},
  journal={Procedia Computer Science},
  volume={3},
  pages={426--433},
  year={2011},
  publisher={Elsevier}
}

@article{bengio2003neural,
  title={A neural probabilistic language model},
  author={Bengio, Yoshua and Ducharme, R{\'e}jean and Vincent, Pascal and Jauvin, Christian},
  journal={Journal of Machine Learning Research},
  volume={3},
  number={6},
  pages={1137--1155},
  year={2003}
}

@inproceedings{nguyen2015relation,
  title={Relation extraction: Perspective from convolutional neural networks},
  author={Nguyen, Thien Huu and Grishman, Ralph},
  booktitle={Proceedings of the 1st Workshop on Vector Space Modeling for Natural Language Processing},
  pages={39--48},
  address={Denver, Colorado},
  publisher={Association for Computational Linguistics},
  year={2015}
}

@inproceedings{xue2018relation,
  title={Relation Extraction Based on Deep Learning},
  author={Xue, Liu and Qing, Song and Pengzhou, Zhang},
  booktitle={2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS)},
  pages={687--691},
  year={2018},
  address={Singapore, Singapore},
  organization={IEEE}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{miwa2016end,
    title = "End-to-End Relation Extraction using {LSTM}s on Sequences and Tree Structures",
    author = "Miwa, Makoto  and
      Bansal, Mohit",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1105",
    doi = "10.18653/v1/P16-1105",
    pages = "1105--1116",
}

@inproceedings{zhang2015bidirectional,
  title={Bidirectional long short-term memory networks for relation classification},
  author={Zhang, Shu and Zheng, Dequan and Hu, Xinchen and Yang, Ming},
  booktitle={Proceedings of the 29th Pacific Asia conference on language, information and computation},
  pages={73--78},
  address={Shanghai, China},
  publisher={Association for Computational Linguistics},
  year={2015}
}

@inproceedings{xu2015classifying,
  title={Classifying relations via long short term memory networks along shortest dependency paths},
  author={Xu, Yan and Mou, Lili and Li, Ge and Chen, Yunchuan and Peng, Hao and Jin, Zhi},
  booktitle={Proceedings of the 2015 conference on empirical methods in natural language processing},
  pages={1785--1794},
  publisher={Association for Computational Linguistics},
  address={Lisbon, Portugal},
  year={2015}
}

@inproceedings{peters2018deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@inproceedings{howard2018universal,
    title = "Universal Language Model Fine-tuning for Text Classification",
    author = "Howard, Jeremy  and
      Ruder, Sebastian",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P18-1031",
    doi = "10.18653/v1/P18-1031",
    pages = "328--339",
    abstract = "Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24{\%} on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100 times more data. We open-source our pretrained models and code.",
}

@book{miller1998wordnet,
  title={WordNet: An electronic lexical database},
  author={Miller, George A},
  year={1998},
  publisher={MIT press}
}

@inproceedings{li2014incremental,
  title={Incremental joint extraction of entity mentions and relations},
  author={Li, Qi and Ji, Heng},
  booktitle={Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={402--412},
  year={2014}
}

@inproceedings{li2016joint,
  title={Joint Models for Extracting Adverse Drug Events from Biomedical Text.},
  author={Li, Fei and Zhang, Yue and Zhang, Meishan and Ji, Donghong},
  booktitle={IJCAI},
  volume={2016},
  pages={2838--2844},
  year={2016}
}

@inproceedings{mooney2006subsequence,
  title={Subsequence kernels for relation extraction},
  author={Mooney, Raymond J and Bunescu, Razvan C},
  booktitle={Advances in neural information processing systems},
  publisher = {MIT Press},
  address = {Cambridge, MA, USA},
  pages={171--178},
  year={2006}
}

@inproceedings{girju2007semeval,
  title={Semeval-2007 task 04: Classification of semantic relations between nominals},
  author={Girju, Roxana and Nakov, Preslav and Nastase, Vivi and Szpakowicz, Stan and Turney, Peter and Yuret, Deniz},
  booktitle={Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007)},
  pages={13--18},
  year={2007}
}

@inproceedings{hendrickx2010semeval,
  title={Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals},
  author={Hendrickx, Iris and Kim, Su Nam and Kozareva, Zornitsa and Nakov, Preslav and S{\'e}aghdha, Diarmuid O and Pad{\'o}, Sebastian and Pennacchiotti, Marco and Romano, Lorenza and Szpakowicz, Stan},
  booktitle={Proceedings of the 5th International Workshop on Semantic Evaluation},
  pages={33--38},
  year={2010},
  organization={Association for Computational Linguistics}
}

@inproceedings{culotta2006integrating,
  title={Integrating probabilistic extraction models and data mining to discover relations and patterns in text},
  author={Culotta, Aron and McCallum, Andrew and Betz, Jonathan},
  booktitle={Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics},
  pages={296--303},
  year={2006},
  organization={Association for Computational Linguistics}
}

@inproceedings{bunescu2007learning,
  title={Learning to extract relations from the web using minimal supervision},
  author={Bunescu, Razvan and Mooney, Raymond},
  booktitle={Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics},
  pages={576--583},
  year={2007}
}

@inproceedings{kim2011overview,
  title={Overview of {B}io{NLP} shared task 2011},
  author={Kim, Jin-Dong and Pyysalo, Sampo and Ohta, Tomoko and Bossy, Robert and Nguyen, Ngan and Tsujii, Jun'ichi},
  booktitle={Proceedings of the BioNLP shared task 2011 workshop},
  pages={1--6},
  year={2011},
  address={Portland, Oregon, USA},
  organization={Association for Computational Linguistics}
}

@article{gurulingappa2012development,
  title={Development of a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical case reports},
  author={Gurulingappa, Harsha and Rajput, Abdul Mateen and Roberts, Angus and Fluck, Juliane and Hofmann-Apitius, Martin and Toldo, Luca},
  journal={Journal of Biomedical Informatics},
  volume={45},
  number={5},
  pages={885--892},
  year={2012},
  publisher={Elsevier}
}

@article{zhang2015relation,
  title={Relation classification via recurrent neural network},
  author={Zhang, Dongxu and Wang, Dong},
  journal={arXiv preprint arXiv:1508.01006},
  year={2015}
}

@inproceedings{fader2011identifying,
author = {Fader, Anthony and Soderland, Stephen and Etzioni, Oren},
title = {Identifying Relations for Open Information Extraction},
year = {2011},
isbn = {9781937284114},
publisher = {Association for Computational Linguistics},
abstract = {Open Information Extraction (IE) is the task of extracting assertions from massive corpora without requiring a pre-specified vocabulary. This paper shows that the output of state-of-the-art Open IE systems is rife with uninformative and incoherent extractions. To overcome these problems, we introduce two simple syntactic and lexical constraints on binary relations expressed by verbs. We implemented the constraints in the ReVerb Open IE system, which more than doubles the area under the precision-recall curve relative to previous extractors such as TextRunner and woepos. More than 30\% of ReVerb's extractions are at precision 0.8 or higher---compared to virtually none for earlier systems. The paper concludes with a detailed analysis of ReVerb's errors, suggesting directions for future work.},
booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
pages = {1535-–1545},
numpages = {11},
address = {Edinburgh, Scotland}
}


@inproceedings{del2013clausie,
author = {Del Corro, Luciano and Gemulla, Rainer},
title = {Claus{IE}: Clause-Based Open Information Extraction},
year = {2013},
isbn = {9781450320351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2488388.2488420},
doi = {10.1145/2488388.2488420},
abstract = {We propose ClausIE, a novel, clause-based approach to open information extraction, which extracts relations and their arguments from natural language text. ClausIE fundamentally differs from previous approaches in that it separates the detection of ``useful'' pieces of information expressed in a sentence from their representation in terms of extractions. In more detail, ClausIE exploits linguistic knowledge about the grammar of the English language to first detect clauses in an input sentence and to subsequently identify the type of each clause according to the grammatical function of its constituents. Based on this information, ClausIE is able to generate high-precision extractions; the representation of these extractions can be flexibly customized to the underlying application. ClausIE is based on dependency parsing and a small set of domain-independent lexica, operates sentence by sentence without any post-processing, and requires no training data (whether labeled or unlabeled). Our experimental study on various real-world datasets suggests that ClausIE obtains higher recall and higher precision than existing approaches, both on high-quality text as well as on noisy text as found in the web.},
booktitle = {Proceedings of the 22nd International Conference on World Wide Web},
pages = {355–-366},
numpages = {12},
keywords = {relation extraction, open information extraction},
location = {Rio de Janeiro, Brazil}
}

@inproceedings{mesquita2013effectiveness,
    title = "Effectiveness and Efficiency of Open Relation Extraction",
    author = "Mesquita, Filipe  and
      Schmidek, Jordan  and
      Barbosa, Denilson",
    booktitle = "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing",
    month = oct,
    year = "2013",
    address = "Seattle, Washington, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D13-1043",
    pages = "447--457",
}

@inproceedings{riedel2010modeling,
  title={Modeling relations and their mentions without labeled text},
  author={Riedel, Sebastian and Yao, Limin and McCallum, Andrew},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={148--163},
  year={2010},
  address={Bilbao, Spain},
  organization={Springer}
}

@article{yadav2019survey,
  title={A survey on recent advances in named entity recognition from deep learning models},
  author={Yadav, Vikas and Bethard, Steven},
  journal={arXiv preprint arXiv:1910.11470},
  year={2019}
}

@inproceedings{ciaramita2006broad,
  title={Broad-coverage sense disambiguation and information extraction with a supersense sequence tagger},
  author={Ciaramita, Massimiliano and Altun, Yasemin},
  booktitle={Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing},
  pages={594--602},
  year={2006},
  address={Sydney, Australia},
  organization={Association for Computational Linguistics}
}

@article{schriml2012disease,
  title={Disease Ontology: a backbone for disease semantic integration},
  author={Schriml, Lynn Marie and Arze, Cesar and Nadendla, Suvarna and Chang, Yu-Wei Wayne and Mazaitis, Mark and Felix, Victor and Feng, Gang and Kibbe, Warren Alden},
  journal={Nucleic Acids Research},
  volume={40},
  number={1},
  pages={940--946},
  year={2012},
  publisher={Oxford University Press}
}

@inproceedings{segura2013semeval,
  title={SemEval-2013 Task 9: Extraction of Drug-Drug Interactions from Biomedical Texts (DDIExtraction 2013)},
  author={Segura-Bedmar, Isabel and Mart{\'\i}nez, Paloma and Herrero-Zazo, Mar{\'\i}a},
  booktitle={Second Joint Conference on Lexical and Computational Semantics (* SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)},
  pages={341--350},
  year={2013}
}

@article{cooper2018planteome,
  title={The Planteome database: an integrated resource for reference ontologies, plant genomics and phenomics},
  author={Cooper, Laurel and Meier, Austin and Laporte, Marie-Ang{\'e}lique and Elser, Justin L and Mungall, Chris and Sinn, Brandon T and Cavaliere, Dario and Carbon, Seth and Dunn, Nathan A and Smith, Barry and others},
  journal={Nucleic Acids Research},
  volume={46},
  number={1},
  pages={1168--1180},
  year={2018},
  publisher={Oxford University Press}
}

@article{huang2016community,
  title={Community challenges in biomedical text mining over 10 years: success, failure and the future},
  author={Huang, Chung-Chi and Lu, Zhiyong},
  journal={Briefings in Bioinformatics},
  volume={17},
  number={1},
  pages={132--144},
  year={2016},
  publisher={Oxford University Press}
}

@article{gruber1993translation,
  title={A translation approach to portable ontology specifications},
  author={Gruber, Thomas R and others},
  journal={Knowledge Acquisition},
  volume={5},
  number={2},
  pages={199--221},
  year={1993},
  publisher={Academic Press}
}

@article{hastings2016chebi,
  title={Ch{EBI} in 2016: Improved services and an expanding collection of metabolites},
  author={Hastings, Janna and Owen, Gareth and Dekker, Adriano and Ennis, Marcus and Kale, Namrata and Muthukrishnan, Venkatesh and Turner, Steve and Swainston, Neil and Mendes, Pedro and Steinbeck, Christoph},
  journal={Nucleic Acids Research},
  volume={44},
  number={1},
  pages={1214--1219},
  year={2016},
  publisher={Oxford University Press}
}

@inproceedings{li2016learning,
  title={Learning word sense embeddings from word sense definitions},
  author={Li, Qi and Li, Tianshi and Chang, Baobao},
  booktitle={Natural Language Understanding and Intelligent Applications: 5th CCF Conference on Natural Language Processing and Chinese Computing and 24th International Conference on Computer Processing of Oriental Languages},
  pages={224--235},
  year={2016},
  address={Kunming, China},
  publisher={Springer}
}

@inproceedings{ma2017ontology,
  title={An ontology-based latent semantic indexing approach using long short-term memory networks},
  author={Ma, Ningning and Zheng, Hai-Tao and Xiao, Xi},
  booktitle={Asia-Pacific Web (APWeb) and Web-Age Information Management (WAIM) Joint Conference on Web and Big Data},
  pages={185--199},
  address={Beijing, China},
  year={2017},
  organization={Springer}
}

@article{goyal2018graph,
  title={Graph embedding techniques, applications, and performance: A survey},
  author={Goyal, Palash and Ferrara, Emilio},
  journal={Knowledge-Based Systems},
  volume={151},
  pages={78--94},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{kong2013multi,
  title={Multi-label classification by mining label and instance correlations from heterogeneous information networks},
  author={Kong, Xiangnan and Cao, Bokai and Yu, Philip S},
  booktitle={Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={614--622},
  address={New York, NY, USA},
  publisher={Association for Computing Machinery},
  year={2013}
}

@inproceedings{dasigi2017ontology,
    title = "Ontology-Aware Token Embeddings for Prepositional Phrase Attachment",
    author = "Dasigi, Pradeep  and
      Ammar, Waleed  and
      Dyer, Chris  and
      Hovy, Eduard",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1191",
    doi = "10.18653/v1/P17-1191",
    pages = "2089--2098",
    abstract = "Type-level word embeddings use the same set of parameters to represent all instances of a word regardless of its context, ignoring the inherent lexical ambiguity in language. Instead, we embed semantic concepts (or synsets) as defined in WordNet and represent a word token in a particular context by estimating a distribution over relevant semantic concepts. We use the new, context-sensitive embeddings in a model for predicting prepositional phrase (PP) attachments and jointly learn the concept embeddings and model parameters. We show that using context-sensitive embeddings improves the accuracy of the PP attachment model by 5.4{\%} absolute points, which amounts to a 34.4{\%} relative reduction in errors.",
}

@article{muller2004textpresso,
  title={Textpresso: an ontology-based information retrieval and extraction system for biological literature},
  author={M{\"u}ller, Hans-Michael and Kenny, Eimear E and Sternberg, Paul W},
  journal={PLoS Biology},
  volume={2},
  number={11},
  pages={1--15},
  year={2004},
  publisher={Public Library of Science}
}

@inproceedings{tripodi2017knowledge,
  title={Knowledge-base-enriched relation extraction},
  author={Tripodi, Ignacio and Boguslav, M and Hailu, N and Hunter, LE},
  booktitle={Proceedings of the Sixth BioCreative Challenge Evaluation Workshop},
  address={Bethesda, MD, USA},
  pages={163--6},
  year={2017}
}

@inproceedings{de2014medical,
author = {De Vine, Lance and Zuccon, Guido and Koopman, Bevan and Sitbon, Laurianne and Bruza, Peter},
title = {Medical Semantic Similarity with a Neural Language Model},
year = {2014},
isbn = {9781450325981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2661829.2661974},
doi = {10.1145/2661829.2661974},
abstract = {Advances in neural network language models have demonstrated that these models can effectively learn representations of words meaning. In this paper, we explore a variation of neural language models that can learn on concepts taken from structured ontologies and extracted from free-text, rather than directly from terms in free-text.This model is employed for the task of measuring semantic similarity between medical concepts, a task that is central to a number of techniques in medical informatics and information retrieval. The model is built with two medical corpora (journal abstracts and patient records) and empirically validated on two ground-truth datasets of human-judged concept pairs assessed by medical professionals. Empirically, our approach correlates closely with expert human assessors (≈0.9) and outperforms a number of state-of-the-art benchmarks for medical semantic similarity.The demonstrated superiority of this model for providing an effective semantic similarity measure is promising in that this may translate into effectiveness gains for techniques in medical information retrieval and medical informatics (e.g., query expansion and literature-based discovery).},
booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
pages = {1819–-1822},
numpages = {4},
keywords = {neural language model, medical information retrieval, distributed representations, word2vec, skip-gram, semantic similarity},
location = {Shanghai, China}
}

@article{xu2018leveraging,
  title={Leveraging biomedical resources in {BI-LSTM} for drug-drug interaction extraction},
  author={Xu, Bo and Shi, Xiufeng and Zhao, Zhehuan and Zheng, Wei},
  journal={IEEE Access},
  volume={6},
  pages={33432--33439},
  year={2018},
  publisher={IEEE}
}

@article{peng2017cross,
  title={Cross-sentence {N}-ary relation extraction with graph {LSTM}s},
  author={Peng, Nanyun and Poon, Hoifung and Quirk, Chris and Toutanova, Kristina and Yih, Wen-tau},
  journal={Transactions of the Association for Computational Linguistics},
  volume={5},
  pages={101--115},
  year={2017},
  publisher={MIT Press}
}

@inproceedings{song2018n,
  title={{N}-ary Relation Extraction using Graph-State {LSTM}},
  author={Song, Linfeng and Zhang, Yue and Wang, Zhiguo and Gildea, Daniel},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={2226--2235},
  publisher={Association for Computational Linguistics},
  address={Brussels, Belgium}, 
  year={2018}
}

@article{wang2017dependency,
  title={Dependency-based long short term memory network for drug-drug interaction extraction},
  author={Wang, Wei and Yang, Xi and Yang, Canqun and Guo, Xiaowei and Zhang, Xiang and Wu, Chengkun},
  journal={BMC Bioinformatics},
  volume={18},
  number={16},
  pages={1--11},
  year={2017},
  publisher={BioMed Central}
}

@article{pesquita2009semantic,
  title={Semantic similarity in biomedical ontologies},
  author={Pesquita, Catia and Faria, Daniel and Falcao, Andre O and Lord, Phillip and Couto, Francisco M},
  journal={PLoS Computational Biology},
  volume={5},
  number={7},
  year={2009},
  publisher={Public Library of Science}
}

@article{lamurias2014identifying,
  title={Identifying interactions between chemical entities in biomedical text},
  author={Lamurias, Andre and Ferreira, Jo{\~a}o D and Couto, Francisco M},
  journal={Journal of Integrative Bioinformatics},
  volume={11},
  number={3},
  pages={1--16},
  year={2014},
  publisher={De Gruyter}
}

@article{couto2019semantic,
  title={Semantic similarity definition},
  author={Couto, F and Lamurias, Andre},
  journal={Encyclopedia of Bioinformatics and Computational Biology},
  volume={1},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{resnik1995using,
  title={Using information content to evaluate semantic similarity in a taxonomy},
  author={Resnik, Philip},
  booktitle={Proceedings of the 14th international joint conference on Artificial intelligence-Volume 1},
  pages={448--453},
  year={1995}
}

@inproceedings{lin1998information,
  title={An information-theoretic definition of similarity.},
  author={Lin, Dekang and others},
  booktitle={Icml},
  pages={296--304},
  year={1998}
}

@article{sousa2020improving,
  title={Improving accessibility and distinction between negative results in biomedical relation extraction},
  author={Sousa, Diana and Lamurias, Andre and Couto, Francisco M},
  journal={Genomics \& Informatics},
  volume={18},
  number={2},
  pages={1--4},
  year={2020},
  publisher={Korea Genome Organization}
}

@inproceedings{jiang2018revisiting,
  title={Revisiting distant supervision for relation extraction},
  author={Jiang, Tingsong and Liu, Jing and Lin, Chin-Yew and Sui, Zhifang},
  booktitle={Proceedings of the Eleventh International Conference on Language Resources and Evaluation},
  pages={3580-3585},
  address={Miyazaki, Japan},
  publisher={European Language Resources Association (ELRA)},
  year={2018}
}

@article{blohm2014negatome,
  title={Negatome 2.0: a database of non-interacting proteins derived by literature mining, manual annotation and protein structure analysis},
  author={Blohm, Philipp and Frishman, Goar and Smialowski, Pawel and Goebels, Florian and Wachinger, Benedikt and Ruepp, Andreas and Frishman, Dmitrij},
  journal={Nucleic Acids Research},
  volume={42},
  number={1},
  pages={396--400},
  year={2014},
  publisher={Oxford University Press}
}

@article{li2020bio,
  title={Bio-semantic relation extraction with attention-based external knowledge reinforcement},
  author={Li, Zhijing and Lian, Yuchen and Ma, Xiaoyong and Zhang, Xiangrong and Li, Chen},
  journal={BMC Bioinformatics},
  volume={21},
  number={1},
  pages={1--18},
  year={2020},
  publisher={Springer}
}

@article{lee2019attention,
  title={Attention models in graphs: A survey},
  author={Lee, John Boaz and Rossi, Ryan A and Kim, Sungchul and Ahmed, Nesreen K and Koh, Eunyee},
  journal={ACM Transactions on Knowledge Discovery from Data (TKDD)},
  volume={13},
  number={6},
  pages={1--25},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@article{ehrlinger2016towards,
  title={Towards a Definition of Knowledge Graphs},
  author={Ehrlinger, Lisa and W{\"o}{\ss}, Wolfram},
  journal={SEMANTiCS (Posters, Demos, SuCCESS)},
  volume={48},
  pages={1--4},
  year={2016}
}

@article{zhou2019hahe,
  title={{HAHE}: Hierarchical attentive heterogeneous information network embedding},
  author={Zhou, Sheng and Bu, Jiajun and Wang, Xin and Chen, Jiawei and Wang, Can},
  journal={arXiv preprint arXiv:1902.01475},
  year={2019}
}

@inproceedings{hosseini2019hierarchical,
  title={Hierarchical Target-Attentive Diagnosis Prediction in Heterogeneous Information Networks},
  author={Hosseini, Anahita and Davis, Tyler and Sarrafzadeh, Majid},
  booktitle={2019 International Conference on Data Mining Workshops},
  pages={949--957},
  address={Beijing, China},
  year={2019},
  organization={IEEE}
}

 @article{yang2020interpretable,
  title={Interpretable and efficient heterogeneous graph convolutional network},
  author={Yang, Yaming and Guan, Ziyu and Li, Jianxin and Zhao, Wei and Cui, Jiangtao and Wang, Quan},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2021},
  pages={1637--1650},
  volume={35},
  number={2},
  publisher={IEEE}
}

@article{wu2020comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2020},
   volume={32},
  number={1},
  pages={4--24},
  publisher={IEEE}
}

@article{kohler2017human,
  title={The human phenotype ontology in 2017},
  author={K{\"o}hler, Sebastian and Vasilevsky, Nicole A and Engelstad, Mark and Foster, Erin and McMurry, Julie and Aym{\'e}, S{\'e}gol{\`e}ne and Baynam, Gareth and Bello, Susan M and Boerkoel, Cornelius F and Boycott, Kym M and others},
  journal={Nucleic Acids Research},
  volume={45},
  number={1},
  pages={865--876},
  year={2017},
  publisher={Oxford University Press}
}

@article{arnaboldi2020text,
  title={Text mining meets community curation: a newly designed curation platform to improve author experience and participation at {W}orm{B}ase},
  author={Arnaboldi, Valerio and Raciti, Daniela and Van Auken, Kimberly and Chan, Juancarlos N and M{\"u}ller, Hans-Michael and Sternberg, Paul W},
  journal={Database},
  volume={2020},
  pages={1--16},
  year={2020},
  publisher={Oxford Academic}
}

@article{tsueng2020applying,
  title={Applying citizen science to gene, drug and disease relationship extraction from biomedical abstracts},
  author={Tsueng, Ginger and Nanis, Max and Fouquier, Jennifer T and Mayers, Michael and Good, Benjamin M and Su, Andrew I},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1226--1233},
  year={2020},
  publisher={Oxford University Press}
}
  
  @inproceedings{miwa2010entity,
  title={Entity-focused sentence simplification for relation extraction},
  author={Miwa, Makoto and S{\ae}tre, Rune and Miyao, Yusuke and Tsujii, Jun’ichi},
  booktitle={Proceedings of the 23rd International Conference on Computational Linguistics},
  address={Beijing, China},
  publisher={Association for Computational Linguistics},
  pages={788--796},
  year={2010}
}

@article{nussbaumer2020excluding,
  title={Excluding non-English publications from evidence-syntheses did not change conclusions: a meta-epidemiological study},
  author={Nussbaumer-Streit, B and Klerings, I and Dobrescu, AI and Persad, E and Stevens, A and Garritty, C and Kamel, C and Affengruber, L and King, VJ and Gartlehner, G},
  journal={Journal of Clinical Epidemiology},
  volume={118},
  pages={42--54},
  year={2020},
  publisher={Elsevier}
}

@article{di2017publish,
  title={Publish (in English) or perish: The effect on citation rate of using languages other than English in scientific publications},
  author={Di Bitetti, Mario S and Ferreras, Juli{\'a}n A},
  journal={Ambio},
  volume={46},
  number={1},
  pages={121--127},
  year={2017},
  publisher={Springer}
}

@INPROCEEDINGS{6103454,
  author={P. {Schone} and T. {Allison} and C. {Giannella} and C. {Pfeifer}},
  booktitle={2011 IEEE 23rd International Conference on Tools with Artificial Intelligence}, 
  title={Bootstrapping Multilingual Relation Discovery Using English Wikipedia and Wikimedia-Induced Entity Extraction}, 
  year={2011},
  volume={},
  number={},
  address={Boca Raton, Florida, USA},
  publisher={IEEE},
  pages={944--951},}
  
  @article{leser2005makes,
  title={What makes a gene name? Named entity recognition in the biomedical literature},
  author={Leser, Ulf and Hakenberg, J{\"o}rg},
  journal={Briefings in Bioinformatics},
  volume={6},
  number={4},
  pages={357--369},
  year={2005},
  publisher={Henry Stewart Publications}
}

@article{horwitz2011naming,
  title={Naming the problem that has no name: creating targets for standardized drugs},
  author={Horwitz, Allan V},
  journal={Studies in History and Philosophy of Biological and Biomedical Sciences},
  volume={42},
  number={4},
  pages={427--433},
  year={2011},
  publisher={Elsevier}
}

@inproceedings{gormley2010non,
  title={Non-expert correction of automatically generated relation annotations},
  author={Gormley, Matthew R and Gerber, Adam and Harper, Mary and Dredze, Mark},
  booktitle={Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk},
  pages={204--207},
  publisher={Association for Computational Linguistics},
  address={Los Angeles, CA, USA},
  year={2010}
}

@inproceedings{collovini2018annotating,
  title={Annotating relations between named entities with crowdsourcing},
  author={Collovini, Sandra and Pereira, Bolivar and dos Santos, Henrique DP and Vieira, Renata},
  booktitle={International Conference on Applications of Natural Language to Information Systems},
  pages={290--297},
  year={2018},
  address={Paris, France},
  organization={Springer}
}

@inproceedings{ipeirotis2010quality,
author = {Ipeirotis, Panagiotis G. and Provost, Foster and Wang, Jing},
title = {Quality Management on Amazon Mechanical Turk},
year = {2010},
isbn = {9781450302227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1837885.1837906},
doi = {10.1145/1837885.1837906},
abstract = {Crowdsourcing services, such as Amazon Mechanical Turk, allow for easy distribution of small tasks to a large number of workers. Unfortunately, since manually verifying the quality of the submitted results is hard, malicious workers often take advantage of the verification difficulty and submit answers of low quality. Currently, most requesters rely on redundancy to identify the correct answers. However, redundancy is not a panacea. Massive redundancy is expensive, increasing significantly the cost of crowdsourced solutions. Therefore, we need techniques that will accurately estimate the quality of the workers, allowing for the rejection and blocking of the low-performing workers and spammers.However, existing techniques cannot separate the true (unrecoverable) error rate from the (recoverable) biases that some workers exhibit. This lack of separation leads to incorrect assessments of a worker's quality. We present algorithms that improve the existing state-of-the-art techniques, enabling the separation of bias and error. Our algorithm generates a scalar score representing the inherent quality of each worker. We illustrate how to incorporate cost-sensitive classification errors in the overall framework and how to seamlessly integrate unsupervised and supervised techniques for inferring the quality of the workers. We present experimental results demonstrating the performance of the proposed algorithm under a variety of settings.},
booktitle = {Proceedings of the ACM SIGKDD Workshop on Human Computation},
pages = {64–-67},
numpages = {4},
location = {Washington DC}
}

@article{khare2015scaling,
  title={Scaling drug indication curation through crowdsourcing},
  author={Khare, Ritu and Burger, John D and Aberdeen, John S and Tresner-Kirsch, David W and Corrales, Theodore J and Hirchman, Lynette and Lu, Zhiyong},
  journal={Database},
  pages={1--10},
  volume={2015},
  year={2015},
  publisher={Narnia}
}

@article{li2016crowdsourcing,
  title={A crowdsourcing workflow for extracting chemical-induced disease relations from free text},
  author={Li, Tong Shu and Bravo, {\`A}lex and Furlong, Laura I and Good, Benjamin M and Su, Andrew I},
  journal={Database},
  volume={2016},
  year={2016},
  pages={1--11},
  publisher={Narnia}
}

@inproceedings{good2014microtask,
  title={Microtask crowdsourcing for disease mention annotation in PubMed abstracts},
  author={Good, Benjamin M and Nanis, Max and Wu, Chunlei and Su, Andrew I},
  booktitle={Pacific Symposium on Biocomputing},
  pages={282--293},
  year={2014},
  address={Kohala Coast, Hawaii, USA},
  organization={World Scientific}
}

@article{sung2020biomedical,
  title={Biomedical Entity Representations with Synonym Marginalization},
  author={Sung, Mujeen and Jeon, Hwisang and Lee, Jinhyuk and Kang, Jaewoo},
  journal={arXiv},
  pages={arXiv--2005},
  year={2020}
}

@inproceedings{jin2020relation,
  title={Relation Extraction Exploiting Full Dependency Forests.},
  author={Jin, Lifeng and Song, Linfeng and Zhang, Yue and Xu, Kun and Ma, Wei-yun and Yu, Dong},
  booktitle={AAAI},
  year={2020},
  pages={8034--8041}
}

@article{campanatti2010health,
  title={Health sciences descriptors in the brazilian speech-language and hearing science.},
  author={Campanatti-Ostiz, H and Andrade, CR},
  journal={Pro-fono: revista de atualizacao cientifica},
  volume={22},
  number={4},
  pages={397},
  year={2010}
}

@inproceedings{papagiannopoulou2016large,
  title={Large-scale semantic indexing and question answering in biomedicine},
  author={Papagiannopoulou, Eirini and Papanikolaou, Yiannis and Dimitriadis, Dimitris and Lagopoulos, Sakis and Tsoumakas, Grigorios and Laliotis, Manos and Markantonatos, Nikos and Vlahavas, Ioannis},
  booktitle={Proceedings of the Fourth BioASQ workshop},
  pages={50--54},
  year={2016}
}

% CHAPTER 3

@article{YU2006252,
title = "Methods in biomedical ontology",
journal = "Journal of Biomedical Informatics",
volume = "39",
number = "3",
pages = "252--266",
year = "2006",
issn = "1532-0464",
author = "Alexander C. Yu",
keywords = "Biomedical ontology, Review, Methods, Ontology design, Ontology evaluation, Ontology maintenance",
abstract = "Research on ontologies is becoming widespread in the biomedical informatics community. At the same time, it has become apparent that the challenges of properly constructing and maintaining ontologies have proven more difficult than many workers in the field initially expected. Discovering general, feasible methods has thus become a central activity for many of those hoping to reap the benefits of ontologies. This paper reviews current methods in the construction, maintenance, alignment, and evaluation of ontologies."
}

@Article{Campaner2011,
author="Campaner, Raffaella",
title="Understanding mechanisms in the health sciences",
journal="Theoretical Medicine and Bioethics",
year="2011",
volume="32",
number="1",
pages="5--17",
abstract="This article focuses on the assessment of mechanistic relations with specific attention to medicine, where mechanistic models are widely employed. I first survey recent contributions in the philosophical literature on mechanistic causation, and then take issue with Federica Russo and Jon Williamson's thesis that two types of evidence, probabilistic and mechanistic, are at stake in the health sciences. I argue instead that a distinction should be drawn between previously acquired knowledge of mechanisms and yet-to-be-discovered knowledge of mechanisms and that both probabilistic evidence and manipulation are essential with respect to newly discovered mechanisms.",
issn="1573-1200"
}

@incollection{BECHTEL2007269,
title = "Biological mechanisms: organized to maintain autonomy",
editor = "Fred C. Boogerd and Frank J. Bruggeman and Jan-Hendrik S. Hofmeyr and Hans V. Westerhoff",
booktitle = "Systems Biology",
publisher = "Elsevier",
address = "Amsterdam, Netherlands",
pages = "269--302",
year = "2007",
isbn = "978-0-444-52085-2",
author = "William Bechtel"
}

@article{Bodenreider08biomedicalontologies,
    author = {O. Bodenreider},
    title = {Biomedical ontologies in action: Role in knowledge management, data integration and decision support},
    journal = {Yearbook Medical Informatics},
    year = {2008},
    volume={17},
    number={01},
    pages = {67--79}
}

@article{10.1093/nar/gky1032,
    author = {Schriml, Lynn M and Mitraka, Elvira and Munro, James and Tauber, Becky and Schor, Mike and Nickle, Lance and Felix, Victor and Jeng, Linda and Bearer, Cynthia and Lichenstein, Richard and Bisordi, Katharine and Campion, Nicole and Hyman, Brooke and Kurland, David and Oates, Connor Patrick and Kibbey, Siobhan and Sreekumar, Poorna and Le, Chris and Giglio, Michelle and Greene, Carol},
    title = "{Human Disease Ontology 2018 update: classification, content and workflow expansion}",
    journal = {Nucleic Acids Research},
    volume = {47},
    number = {1},
    pages = {955--962},
    year = {2018},
    abstract = "{The Human Disease Ontology (DO) (http://www.disease-ontology.org), database has undergone significant expansion in the past three years. The DO disease classification includes specific formal semantic rules to express meaningful disease models and has expanded from a single asserted classification to include multiple-inferred mechanistic disease classifications, thus providing novel perspectives on related diseases. Expansion of disease terms, alternative anatomy, cell type and genetic disease classifications and workflow automation highlight the updates for the DO since 2015. The enhanced breadth and depth of the DO’s knowledgebase has expanded the DO’s utility for exploring the multi-etiology of human disease, thus improving the capture and communication of health-related data across biomedical databases, bioinformatics tools, genomic and cancer resources and demonstrated by a 6.6× growth in DO’s user community since 2015. The DO’s continual integration of human disease knowledge, evidenced by the more than 200 SVN/GitHub releases/revisions, since previously reported in our DO 2015 NAR paper, includes the addition of 2650 new disease terms, a 30\% increase of textual definitions, and an expanding suite of disease classification hierarchies constructed through defined logical axioms.}",
    issn = {0305-1048}
}

@INPROCEEDINGS{Pyysalo:2013b,
     author = {Pyysalo, S. and Ginter, F. and Moen, H. and Salakoski, T. and Ananiadou, S.},
      title = {Distributional Semantics Resources for Biomedical Text Processing},
  booktitle = {Proceedings
of the 5th International Symposium
on Languages in Biology and Medicine},
       year = {2013},
      address={Tokyo, Japan},
      publisher={Database Center for Life Science},
      pages = {39--44}}

@article{journals/corr/abs-1207-0580,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  interhash = {3e6590885191244531ef7ce34bb388d0},
  intrahash = {852239c1ed83a86f637f80bc641333b6},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T15:24:04.000+0200},
  title = {Improving neural networks by preventing co-adaptation of feature detectors},
  volume = {abs/1207.0580},
  year = 2012
}

@inproceedings{inproceedingscdr,
  title={Overview of the {B}io{C}reative {V} chemical disease relation {(CDR)} task},
  author={Wei, Chih-Hsuan and Peng, Yifan and Leaman, Robert and Davis, Allan Peter and Mattingly, Carolyn J and Li, Jiao and Wiegers, Thomas C and Lu, Zhiyong},
  booktitle={Proceedings of the fifth BioCreative challenge evaluation workshop},
  pages={1--9},
  address={Sevilla, Spain},
  year={2015}
}

@incollection{COUTO2019870,
title = "Semantic Similarity Definition",
editor = "Shoba Ranganathan and Michael Gribskov and Kenta Nakai and Christian Schönbach",
booktitle = "Encyclopedia of Bioinformatics and Computational Biology",
publisher = "Academic Press",
address = "Oxford, England",
pages = "870--876",
year = "2019",
isbn = "978-0-12-811432-2",
author = "Francisco M. Couto and Andre Lamurias"
}

% CHAPTER 4

@inproceedings{10.1145/3308558.3313705,
author = {Cao, Yixin and Wang, Xiang and He, Xiangnan and Hu, Zikun and Chua, Tat-Seng},
title = {Unifying Knowledge Graph Learning and Recommendation: Towards a Better Understanding of User Preferences},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
abstract = {Incorporating knowledge graph (KG) into recommender system is promising in improving the recommendation accuracy and explainability. However, existing methods largely assume that a KG is complete and simply transfer the ”knowledge” in KG at the shallow level of entity raw data or embeddings. This may lead to suboptimal performance, since a practical KG can hardly be complete, and it is common that a KG has missing facts, relations, and entities. Thus, we argue that it is crucial to consider the incomplete nature of KG when incorporating it into recommender system. In this paper, we jointly learn the model of recommendation and knowledge graph completion. Distinct from previous KG-based recommendation methods, we transfer the relation information in KG, so as to understand the reasons that a user likes an item. As an example, if a user has watched several movies directed by (relation) the same person (entity), we can infer that the director relation plays a critical role when the user makes the decision, thus help to understand the user's preference at a finer granularity. Technically, we contribute a new translation-based recommendation model, which specially accounts for various preferences in translating a user to an item, and then jointly train it with a KG completion model by combining several transfer schemes. Extensive experiments on two benchmark datasets show that our method outperforms state-of-the-art KG-based recommendation methods. Further analysis verifies the positive effect of joint training on both tasks of recommendation and KG completion, and the advantage of our model in understanding user preference. We publish our project at https://github.com/TaoMiner/joint-kg-recommender.},
booktitle = {The World Wide Web Conference},
pages = {151–-161},
numpages = {11},
keywords = {Knowledge Graph, Embedding, Joint Model, Item Recommendation},
address = {San Francisco, CA, USA}
}

@article{10.1145/2827872,
author = {Harper, F. Maxwell and Konstan, Joseph A.},
title = {The {M}ovie{L}ens Datasets: History and Context},
year = {2015},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
issn = {2160-6455},
abstract = {The MovieLens datasets are widely used in education, research, and industry. They are downloaded hundreds of thousands of times each year, reflecting their use in popular press programming books, traditional and online courses, and software. These datasets are a product of member activity in the MovieLens movie recommendation system, an active research platform that has hosted many experiments since its launch in 1997. This article documents the history of MovieLens and the MovieLens datasets. We include a discussion of lessons learned from running a long-standing, live research platform from the perspective of a research organization. We document best practices and limitations of using the MovieLens datasets in new research.},
journal = {ACM Transactions on Interactive Intelligent Systems},
pages = {1--19},
articleno = {19},
numpages = {19},
keywords = {MovieLens, Datasets, recommendations, ratings}
}

@article{10.1371/journal.pbio.2005343,
    author = {Fiorini, Nicolas AND Canese, Kathi AND Starchenko, Grisha AND Kireev, Evgeny AND Kim, Won AND Miller, Vadim AND Osipov, Maxim AND Kholodov, Michael AND Ismagilov, Rafis AND Mohan, Sunil AND Ostell, James AND Lu, Zhiyong},
    journal = {PLOS Biology},
    publisher = {Public Library of Science},
    title = {Best Match: New relevance search for PubMed},
    year = {2018},
    volume = {16},
    pages = {1--12},
    abstract = {PubMed is a free search engine for biomedical literature accessed by millions of users from around the world each day. With the rapid growth of biomedical literature—about two articles are added every minute on average—finding and retrieving the most relevant papers for a given query is increasingly challenging. We present Best Match, a new relevance search algorithm for PubMed that leverages the intelligence of our users and cutting-edge machine-learning technology as an alternative to the traditional date sort order. The Best Match algorithm is trained with past user searches with dozens of relevance-ranking signals (factors), the most important being the past usage of an article, publication date, relevance score, and type of article. This new algorithm demonstrates state-of-the-art retrieval performance in benchmarking experiments as well as an improved user experience in real-world testing (over 20\% increase in user click-through rate). Since its deployment in June 2017, we have observed a significant increase (60\%) in PubMed searches with relevance sort order: it now assists millions of PubMed searches each week. In this work, we hope to increase the awareness and transparency of this new relevance sort option for PubMed users, enabling them to retrieve information more effectively.},
    number = {8},
}

@ARTICLE{8416973,
  author={Tom {Young} and Devamanyu {Hazarika} and Soujanya {Poria} and Erik {Cambria}},
  journal={IEEE Computational Intelligence Magazine}, 
  title={Recent Trends in Deep Learning Based Natural Language Processing [Review Article]}, 
  year={2018},
  volume={13},
  number={3},
  pages={55--75},
}

@book{indurkhya2010handbook,
  title={Handbook of natural language processing},
  author={Indurkhya, Nitin and Damerau, Fred J},
  year={2010},
  address={Cleveland, Ohio, EUA},
  publisher={CRC Press}
}

@article{hastings2012chebi,
  title={The {C}h{EBI} reference database and ontology for biologically relevant chemistry: enhancements for 2013},
  author={Hastings, Janna and de Matos, Paula and Dekker, Adriano and Ennis, Marcus and Harsha, Bhavana and Kale, Namrata and Muthukrishnan, Venkatesh and Owen, Gareth and Turner, Steve and Williams, Mark and others},
  journal={Nucleic Acids Research},
  volume={41},
  number={1},
  pages={456--463},
  year={2012},
  publisher={Oxford University Press}
}

@article{kohler2019expansion,
  title={Expansion of the Human Phenotype Ontology {(HPO)} knowledge base and resources},
  author={K{\"o}hler, Sebastian and Carmody, Leigh and Vasilevsky, Nicole and Jacobsen, Julius O B and Danis, Daniel and Gourdine, Jean-Philippe and Gargano, Michael and Harris, Nomi L and Matentzoglu, Nicolas and McMurry, Julie A and others},
  journal={Nucleic Acids Research},
  volume={47},
  number={1},
  pages={1018--1027},
  year={2019},
  publisher={Oxford University Press}
}


@article{barros2019using,
  title={Using research literature to generate datasets of implicit feedback for recommending scientific items},
  author={Barros, M{\'a}rcia and Moitinho, Andr{\'e} and Couto, Francisco M},
  journal={IEEE Access},
  volume={7},
  pages={176668--176680},
  year={2019},
  publisher={IEEE}
}

@ARTICLE{9216015,
  author={Qingyu {Guo} and Fuzhen {Zhuang} and Chuan {Qin} and Hengshu {Zhu} and Xing {Xie} and Hui {Xiong} and Qing {He}},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Survey on Knowledge Graph-Based Recommender Systems}, 
  year={2020},
volume={34},
  number={8},
  pages={3549--3568},
}

@inproceedings{10.1145/2959100.2959190,
author = {Covington, Paul and Adams, Jay and Sargin, Emre},
title = {Deep Neural Networks for YouTube Recommendations},
year = {2016},
isbn = {9781450340359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact.},
booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
pages = {191–-198},
numpages = {8},
keywords = {deep learning, scalability, recommender system},
location = {Boston, Massachusetts, USA}
}

@inproceedings{10.1145/3109859.3109872,
author = {Jannach, Dietmar and Ludewig, Malte},
title = {When Recurrent Neural Networks Meet the Neighborhood for Session-Based Recommendation},
year = {2017},
isbn = {9781450346528},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Deep learning methods have led to substantial progress in various application fields of AI, and in recent years a number of proposals were made to improve recommender systems with artificial neural networks. For the problem of making session-based recommendations, i.e., for recommending the next item in an anonymous session, Hidasi et al.~recently investigated the application of recurrent neural networks with Gated Recurrent Units (GRU4REC). Assessing the true effectiveness of such novel approaches based only on what is reported in the literature is however difficult when no standard evaluation protocols are applied and when the strength of the baselines used in the performance comparison is not clear. In this work we show based on a comprehensive empirical evaluation that a heuristics-based nearest neighbor (kNN) scheme for sessions outperforms GRU4REC in the large majority of the tested configurations and datasets. Neighborhood sampling and efficient in-memory data structures ensure the scalability of the kNN method. The best results in the end were often achieved when we combine the kNN approach with GRU4REC, which shows that RNNs can leverage sequential signals in the data that cannot be detected by the co-occurrence-based kNN method.},
booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
pages = {306–-310},
numpages = {5},
keywords = {session-based recommendation, nearest-neighbors, deep learning},
location = {Como, Italy}
}

@article{huang2020efficient,
  title={An efficient group recommendation model with multiattention-based neural networks},
  author={Huang, Zhenhua and Xu, Xin and Zhu, Honghao and Zhou, MengChu},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  volume={31},
  number={11},
  pages={4461--4474},
  year={2020},
  publisher={IEEE}
}

@article{guo2017resolving,
  title={Resolving data sparsity by multi-type auxiliary implicit feedback for recommender systems},
  author={Guo, Guibing and Qiu, Huihuai and Tan, Zhenhua and Liu, Yuan and Ma, Jing and Wang, Xingwei},
  journal={Knowledge-Based Systems},
  volume={138},
  pages={202--207},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{10.1145/3397271.3401426,
author = {Bi, Ye and Song, Liqiang and Yao, Mengqiu and Wu, Zhenyu and Wang, Jianming and Xiao, Jing},
title = {A Heterogeneous Information Network Based Cross Domain Insurance Recommendation System for Cold Start Users},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Internet is changing the world, adapting to the trend of internet sales will bring revenue to traditional insurance companies. Online insurance is still in its early stages of development, where cold start problem (prospective customer) is one of the greatest challenges. In traditional e-commerce field, several cross-domain recommendation (CDR) methods have been studied to infer preferences of cold start users based on their preferences in other domains. However, these CDR methods couldn't be applied to insurance domain directly due to the domain's specific properties. In this paper, we propose a novel framework called a Heterogeneous information network based Cross Domain Insurance Recommendation (HCDIR) system for cold start users. Specifically, we first try to learn more effective user and item latent features in both source and target domains. In source domain, we employ gated recurrent unit (GRU) to module users' dynamic interests. In target domain, given the complexity of insurance products and the data sparsity problem, we construct an insurance heterogeneous information network (IHIN) based on data from PingAn Jinguanjia, the IHIN connects users, agents, insurance products and insurance product properties together, giving us richer information. Then we employ three-level (relational, node, and semantic) attention aggregations to get user and insurance product representations. After obtaining latent features of overlapping users, a feature mapping between the two domains is learned by multi-layer perceptron (MLP). We apply HCDIR on Jinguanjia dataset, and show HCDIR significantly outperforms the state-of-the-art solutions.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2211–-2220},
numpages = {10}
}

@article{10.1145/3309547,
author = {Feng, Fuli and He, Xiangnan and Wang, Xiang and Luo, Cheng and Liu, Yiqun and Chua, Tat-Seng},
title = {Temporal Relational Ranking for Stock Prediction},
year = {2019},
issue_date = {March 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {37},
number = {2},
pages={1-30},
issn = {1046-8188},
abstract = {Stock prediction aims to predict the future trends of a stock in order to help investors make good investment decisions. Traditional solutions for stock prediction are based on time-series models. With the recent success of deep neural networks in modeling sequential data, deep learning has become a promising choice for stock prediction.However, most existing deep learning solutions are not optimized toward the target of investment, i.e., selecting the best stock with the highest expected revenue. Specifically, they typically formulate stock prediction as a classification (to predict stock trends) or a regression problem (to predict stock prices). More importantly, they largely treat the stocks as independent of each other. The valuable signal in the rich relations between stocks (or companies), such as two stocks are in the same sector and two companies have a supplier-customer relation, is not considered.In this work, we contribute a new deep learning solution, named Relational Stock Ranking (RSR), for stock prediction. Our RSR method advances existing solutions in two major aspects: (1) tailoring the deep learning models for stock ranking, and (2) capturing the stock relations in a time-sensitive manner. The key novelty of our work is the proposal of a new component in neural network modeling, named Temporal Graph Convolution, which jointly models the temporal evolution and relation network of stocks. To validate our method, we perform back-testing on the historical data of two stock markets, NYSE and NASDAQ. Extensive experiments demonstrate the superiority of our RSR method. It outperforms state-of-the-art stock prediction solutions achieving an average return ratio of 98\% and 71\% on NYSE and NASDAQ, respectively.},
journal = {ACM Transactions on Information Systems},
articleno = {27},
numpages = {30},
keywords = {Stock prediction, graph-based learning, learning to rank}
}

@article{ai2018learning,
  title={Learning heterogeneous knowledge base embeddings for explainable recommendation},
  author={Ai, Qingyao and Azizi, Vahid and Chen, Xu and Zhang, Yongfeng},
  journal={Algorithms},
  volume={11},
  number={9},
  pages={1--17},
  year={2018},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@inproceedings{10.1145/3308558.3313411,
author = {Wang, Hongwei and Zhang, Fuzheng and Zhao, Miao and Li, Wenjie and Xie, Xing and Guo, Minyi},
title = {Multi-Task Feature Learning for Knowledge Graph Enhanced Recommendation},
year = {2019},
isbn = {9781450366748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Collaborative filtering often suffers from sparsity and cold start problems in real recommendation scenarios, therefore, researchers and engineers usually use side information to address the issues and improve the performance of recommender systems. In this paper, we consider knowledge graphs as the source of side information. We propose MKR, a Multi-task feature learning approach for Knowledge graph enhanced Recommendation. MKR is a deep end-to-end framework that utilizes knowledge graph embedding task to assist recommendation task. The two tasks are associated by crosscompress units, which automatically share latent features and learn high-order interactions between items in recommender systems and entities in the knowledge graph. We prove that crosscompress units have sufficient capability of polynomial approximation, and show that MKR is a generalized framework over several representative methods of recommender systems and multi-task learning. Through extensive experiments on real-world datasets, we demonstrate that MKR achieves substantial gains in movie, book, music, and news recommendation, over state-of-the-art baselines. MKR is also shown to be able to maintain satisfactory performance even if user-item interactions are sparse.},
booktitle = {The World Wide Web Conference},
pages = {2000–-2010},
numpages = {11},
keywords = {Multi-task learning, Knowledge graph, Recommender systems},
location = {San Francisco, CA, USA}
}

@inproceedings{PMID:30441232,
title = {{SCOSY}: A Biomedical Collaboration Recommendation System},
author = {Guerra, Jorge and Quan, Wei and Li, Kai and Ahumada, Luis and Winston, Flaura and Desai, Bimal},
address={Honolulu, Hawaii, USA},
year = {2018},
booktitle = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
ISSN = {2375-7477},
pages = {3987-—3990},
Abstract = {Finding relevant scientific articles and collaborators is a time-consuming and challenging task in today's information-rich environment. Despite this challenge, the study and development of recommendation systems, based on the authors' collaboration network, productivity and area of research, as topics of interest, have not been practically deployed in healthcare organizations. To address this known practice gap and to promote collaboration, Schosy was developed. This system collects publication metadata from PubMed, as the data source, and combining Collaborative and ContentBased Filtering techniques coupled with the Latent Dirichlet Allocation Topic Modeling algorithm, it recommends collaborators based on the authors' work, collaboration among the authors, Medical Subject Headings (MeSH) terms and the productivity of relevant researchers. As a result, this system provides an interpretable latent structure for collaborators and biomedical databases in order to enhance the experience of finding collaboration, for and by researchers and non-technical users.},
publisher={IEEE}
}

@Article{info:doi/10.2196/12957,
author="Feng, Xiaoyue
and Zhang, Hao
and Ren, Yijie
and Shang, Penghui
and Zhu, Yi
and Liang, Yanchun
and Guan, Renchu
and Xu, Dong",
title="The Deep Learning--Based Recommender System ``Pubmender'' for Choosing a Biomedical Publication Venue: Development and Validation Study",
journal="Journal of Medical Internet Research",
year="2019",
volume="21",
number="5",
pages="1--12",
keywords="recommender system; deep learning; convolutional neural network; biomedical literature; PubMed",
abstract="Background: It is of great importance for researchers to publish research results in high-quality journals. However, it is often challenging to choose the most suitable publication venue, given the exponential growth of journals and conferences. Although recommender systems have achieved success in promoting movies, music, and products, very few studies have explored recommendation of publication venues, especially for biomedical research. No recommender system exists that can specifically recommend journals in PubMed, the largest collection of biomedical literature. Objective: We aimed to propose a publication recommender system, named Pubmender, to suggest suitable PubMed journals based on a paper's abstract. Methods: In Pubmender, pretrained word2vec was first used to construct the start-up feature space. Subsequently, a deep convolutional neural network was constructed to achieve a high-level representation of abstracts, and a fully connected softmax model was adopted to recommend the best journals. Results: We collected 880,165 papers from 1130 journals in PubMed Central and extracted abstracts from these papers as an empirical dataset. We compared different recommendation models such as Cavnar-Trenkle on the Microsoft Academic Search (MAS) engine, a collaborative filtering--based recommender system for the digital library of the Association for Computing Machinery (ACM) and CiteSeer. We found the accuracy of our system for the top 10 recommendations to be 87.0{\%}, 22.9{\%}, and 196.0{\%} higher than that of MAS, ACM, and CiteSeer, respectively. In addition, we compared our system with Journal Finder and Journal Suggester, which are tools of Elsevier and Springer, respectively, that help authors find suitable journals in their series. The results revealed that the accuracy of our system was 329{\%} higher than that of Journal Finder and 406{\%} higher than that of Journal Suggester for the top 10 recommendations. Our web service is freely available at https://www.keaml.cn:8081/. Conclusions: Our deep learning--based recommender system can suggest an appropriate journal list to help biomedical scientists and clinicians choose suitable venues for their papers. ",
issn="1438-8871"
}

@article{martinez2017ncbo,
  title={{NCBO} Ontology Recommender 2.0: an enhanced approach for biomedical ontology recommendation},
  author={Mart{\'\i}nez-Romero, Marcos and Jonquet, Clement and O’connor, Martin J and Graybeal, John and Pazos, Alejandro and Musen, Mark A},
  journal={Journal of Biomedical Semantics},
  volume={8},
  number={1},
  pages={1--22},
  year={2017},
  publisher={BioMed Central}
}

@article{wang2020independent,
  title={Independent path-based process recommendation algorithm for improving biomedical process modelling},
  author={Wang, Jiaxing and Tan, Dapeng and Cao, Bin and Fan, Jing and Deep, Samundra},
  journal={Electronics Letters},
  volume={56},
  number={11},
  pages={531--533},
  year={2020},
  publisher={IET}
}

@Article{info:doi/10.2196/21169,
author="Gates, Lyndsey Elaine
and Hamed, Ahmed Abdeen",
title="The Anatomy of the {SARS}-Co{V}-2 Biomedical Literature: Introducing the CovidX Network Algorithm for Drug Repurposing Recommendation",
journal="Journal of Medical Internet Research",
year="2020",
volume="22",
number="8",
pages="1--17",
keywords="health; informatics; COVID-19 treatment; drug repurposing; network algorithm; ranking; drug; biomedical; antiviral; COVID-19",
abstract="Background: Driven by the COVID-19 pandemic and the dire need to discover an antiviral drug, we explored the landscape of the SARS-CoV-2 biomedical publications to identify potential treatments. Objective: The aims of this study are to identify off-label drugs that may have benefits for the coronavirus disease pandemic, present a novel ranking algorithm called CovidX to recommend existing drugs for potential repurposing, and validate the literature-based outcome with drug knowledge available in clinical trials. Methods: To achieve such objectives, we applied natural language processing techniques to identify drugs and linked entities (eg, disease, gene, protein, chemical compounds). When such entities are linked, they form a map that can be further explored using network science tools. The CovidX algorithm was based upon a notion that we called ``diversity.'' A diversity score for a given drug was calculated by measuring how ``diverse'' a drug is calculated using various biological entities (regardless of the cardinality of actual instances in each category). The algorithm validates the ranking and awards those drugs that are currently being investigated in open clinical trials. The rationale behind the open clinical trial is to provide a validating mechanism of the PubMed results. This ensures providing up to date evidence of the fast development of this disease. Results: From the analyzed biomedical literature, the algorithm identified 30 possible drug candidates for repurposing, ranked them accordingly, and validated the ranking outcomes against evidence from clinical trials. The top 10 candidates according to our algorithm are hydroxychloroquine, azithromycin, chloroquine, ritonavir, losartan, remdesivir, favipiravir, methylprednisolone, rapamycin, and tilorone dihydrochloride. Conclusions: The ranking shows both consistency and promise in identifying drugs that can be repurposed. We believe, however, the full treatment to be a multifaceted, adjuvant approach where multiple drugs may need to be taken at the same time. ",
issn="1438-8871"
}

@inproceedings{yang2018keyword,
  title={A keyword-based scholar recommendation framework for biomedical literature},
  author={Yang, Fen and Zhu, Jia and Lun, Jiaqi and Zheng, Zetao and Tang, Yong and Wu, Jian},
  booktitle={2018 IEEE 22nd International Conference on Computer Supported Cooperative Work in Design},
  pages={247--252},
  year={2018},
  address={Nanjing, China}, 
  organization={IEEE}
}

@article{PATRA2020103399,
title = "A content-based literature recommendation system for datasets to improve data reusability – A case study on Gene Expression Omnibus {(GEO)} datasets",
journal = "Journal of Biomedical Informatics",
volume = "104",
pages = "1--8",
year = "2020",
issn = "1532-0464",
author = "Braja Gopal Patra and Vahed Maroufy and Babak Soltanalizadeh and Nan Deng and W. Jim Zheng and Kirk Roberts and Hulin Wu",
keywords = "Literature recommendation, Gene Expression Omnibus (GEO), Vector space model, Cosine similarity, Re-ranking",
abstract = "Objective
The centrality of data to biomedical research is difficult to understate, and the same is true for the importance of the biomedical literature in disseminating empirical findings to scientific questions made on such data. But the connections between the literature and related datasets are often weak, hampering the ability of scientists to easily move between existing datasets and existing findings to derive new scientific hypotheses. This work aims to recommend relevant literature articles for datasets with the ultimate goal of increasing the productivity of researchers. Our approach to literature recommendation for datasets is a part of the dataset reusability platform developed at the University Texas Health Science Center at Houston for datasets related to gene expression. This platform incorporates datasets from Gene Expression Omnibus (GEO). An average of 34 datasets were added to GEO daily in the last five years (i.e. 2014 to 2018), demonstrating the need for automatic methods to connect these datasets with relevant literature. The relevant literature for a given dataset may describe that dataset, provide a scientific finding based on that dataset, or even describe prior and related work to the dataset’s topic that is of interest to users of the dataset.
Materials and methods
We adopt an information retrieval paradigm for literature recommendation. In our experiments, distributional semantic features are created from the title and abstract of MEDLINE articles. Then, related articles are identified for datasets in GEO. We evaluate multiple distributional methods such as TF-IDF, BM25, Latent Semantic Analysis, Latent Dirichlet Allocation, word2vec, and doc2vec. Top similar papers are recommended for each dataset using cosine similarity between the dataset’s vector representation and every paper’s vector representation. We also propose several novel re-ranking and normalization methods over embeddings to improve the recommendations.
Results
The top-performing literature recommendation technique achieved a strict precision at 10 of 0.8333 and a partial precision at 10 of 0.9000 using BM25 based on a manual evaluation of 36 datasets. Evaluation on a larger, automatically-collected benchmark shows small but consistent gains by emphasizing the similarity of dataset and article titles.
Conclusion
This work is the first step toward developing a literature recommendation tool by recommending relevant literature for datasets. This will hopefully lead to better data reuse experience."
}

@article{yuan2020constructing,
  title={Constructing biomedical domain-specific knowledge graph with minimum supervision},
  author={Yuan, Jianbo and Jin, Zhiwei and Guo, Han and Jin, Hongxia and Zhang, Xianchao and Smith, Tristram and Luo, Jiebo},
  journal={Knowledge and Information Systems},
  volume={62},
  number={1},
  pages={317--336},
  year={2020},
  publisher={Springer}
}

@article{zhang2021drug,
  title={Drug Repurposing for Parkinson’s Disease by Integrating Knowledge Graph Completion Model and Knowledge Fusion of Medical Literature},
  author={Zhang, Xiaolin and Che, Chao},
  journal={Future Internet},
  volume={13},
  number={1},
  pages={1--13},
  year={2021},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{fei2020enriching,
    author = {Fei, Hao and Ren, Yafeng and Zhang, Yue and Ji, Donghong and Liang, Xiaohui},
    title = "{Enriching contextualized language model from knowledge graph for biomedical information extraction}",
    journal = {Briefings in Bioinformatics},
    volume = {22},
    number = {3},
    pages={1--14},
    year = {2020},
    abstract = "{Biomedical information extraction (BioIE) is an important task. The aim is to analyze biomedical texts and extract structured information such as named entities and semantic relations between them. In recent years, pre-trained language models have largely improved the performance of BioIE. However, they neglect to incorporate external structural knowledge, which can provide rich factual information to support the underlying understanding and reasoning for biomedical information extraction. In this paper, we first evaluate current extraction methods, including vanilla neural networks, general language models and pre-trained contextualized language models on biomedical information extraction tasks, including named entity recognition, relation extraction and event extraction. We then propose to enrich a contextualized language model by integrating a large scale of biomedical knowledge graphs (namely, BioKGLM). In order to effectively encode knowledge, we explore a three-stage training procedure and introduce different fusion strategies to facilitate knowledge injection. Experimental results on multiple tasks show that BioKGLM consistently outperforms state-of-the-art extraction models. A further analysis proves that BioKGLM can capture the underlying relations between biomedical knowledge concepts, which are crucial for BioIE. }",
    issn = {1477-4054},
    doi = {10.1093/bib/bbaa110},
    url = {https://doi.org/10.1093/bib/bbaa110},
    eprint = {https://academic.oup.com/bib/article-pdf/22/3/bbaa110/37963251/bbaa110.pdf},
}

@article{biswas2019relation,
  title={Relation prediction of co-morbid diseases using knowledge graph completion},
  author={Biswas, Saikat and Mitra, Pabitra and Rao, Krothapalli Sreenivasa},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics},
  year={2019},
  numpages={10},
  volume={18},
  number={2},
  pages={708-–717},
  publisher={IEEE}
}

@inproceedings{10.1145/3397271.3401032,
author = {Balog, Krisztian and Radlinski, Filip},
title = {Measuring Recommendation Explanation Quality: The Conflicting Goals of Explanations},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Explanations have a large effect on how people respond to recommendations. However, there are many possible intentions a system may have in generating explanations for a given recommendation -from increasing transparency, to enabling a faster decision, to persuading the recipient. As a good explanation for one goal may not be good for others, we address the questions of (1) how to robustly measure if an explanation meets a given goal and (2) how the different goals interact with each other. Specifically, this paper presents a first proposal of how to measure the quality of explanations along seven common goal dimensions catalogued in the literature. We find that the seven goals are not independent, but rather exhibit strong structure. Proposing two novel explanation evaluation designs, we identify challenges in evaluation, and provide more efficient measurement approaches of explanation quality.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {329–-338},
numpages = {10}
}

@inproceedings{10.1145/3397271.3401428,
author = {Feng, Yufei and Hu, Binbin and Lv, Fuyu and Liu, Qingwen and Zhang, Zhiqiang and Ou, Wenwu},
title = {{ATBRG}: Adaptive Target-Behavior Relational Graph Network for Effective Recommendation},
year = {2020},
isbn = {9781450380164},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Recommender system (RS) devotes to predicting user preference to a given item and has been widely deployed in most web-scale applications. Recently, knowledge graph (KG) attracts much attention in RS due to its abundant connective information. Existing methods either explore independent meta-paths for user-item pairs over KG, or employ graph neural network (GNN) on whole KG to produce representations for users and items separately. Despite effectiveness, the former type of methods fails to fully capture structural information implied in KG, while the latter ignores the mutual effect between target user and item during the embedding propagation. In this work, we propose a new framework named Adaptive Target-Behavior Relational Graph network (ATBRG for short) to effectively capture structural relations of target user-item pairs over KG. Specifically, to associate the given target item with user behaviors over KG, we propose the graph connect and graph prune techniques to construct adaptive target-behavior relational graph. To fully distill structural information from the sub-graph connected by rich relations in an end-to-end fashion, we elaborate on the model design of ATBRG, equipped with relation-aware extractor layer and representation activation layer. We perform extensive experiments on both industrial and benchmark datasets. Empirical results show that ATBRG consistently and significantly outperforms state-of-the-art methods. Moreover, ATBRG has also achieved a performance improvement of 5.1\% on CTR metric after successful deployment in one popular recommendation scenario of Taobao APP.},
booktitle = {Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2231–-2240},
numpages = {10}
}

@incollection{sousa2021using,
  title={Using neural networks for relation extraction from biomedical literature},
  author={Sousa, Diana and Lamurias, Andre and Couto, Francisco M},
  booktitle={Artificial Neural Networks},
  pages={289--305},
  year={2021},
  address={New York, NY, USA},
  publisher={Springer}
}

@inproceedings{verga-etal-2018-simultaneously,
    title = "Simultaneously Self-Attending to All Mentions for Full-Abstract Biological Relation Extraction",
    author = "Verga, Patrick  and
      Strubell, Emma  and
      McCallum, Andrew",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    pages = "872--884",
    abstract = "Most work in relation extraction forms a prediction by looking at a short span of text within a single sentence containing a single entity pair mention. This approach often does not consider interactions across mentions, requires redundant computation for each mention pair, and ignores relationships expressed across sentence boundaries. These problems are exacerbated by the document- (rather than sentence-) level annotation common in biological text. In response, we propose a model which simultaneously predicts relationships between all mention pairs in a document. We form pairwise predictions over entire paper abstracts using an efficient self-attention encoder. All-pairs mention scores allow us to perform multi-instance learning by aggregating over mentions to form entity pair representations. We further adapt to settings without mention-level annotation by jointly training to predict named entities and adding a corpus of weakly labeled data. In experiments on two Biocreative benchmark datasets, we achieve state of the art performance on the Biocreative V Chemical Disease Relation dataset for models without external KB resources. We also introduce a new dataset an order of magnitude larger than existing human-annotated biological information extraction datasets and more accurate than distantly supervised alternatives.",
}

@inproceedings{10.1145/3289600.3290956,
author = {Huang, Xiao and Zhang, Jingyuan and Li, Dingcheng and Li, Ping},
title = {Knowledge Graph Embedding Based Question Answering},
year = {2019},
isbn = {9781450359405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Question answering over knowledge graph (QA-KG) aims to use facts in the knowledge graph (KG) to answer natural language questions. It helps end users more efficiently and more easily access the substantial and valuable knowledge in the KG, without knowing its data structures. QA-KG is a nontrivial problem since capturing the semantic meaning of natural language is difficult for a machine. Meanwhile, many knowledge graph embedding methods have been proposed. The key idea is to represent each predicate/entity as a low-dimensional vector, such that the relation information in the KG could be preserved. The learned vectors could benefit various applications such as KG completion and recommender systems. In this paper, we explore to use them to handle the QA-KG problem. However, this remains a challenging task since a predicate could be expressed in different ways in natural language questions. Also, the ambiguity of entity names and partial names makes the number of possible answers large. To bridge the gap, we propose an effective Knowledge Embedding based Question Answering (KEQA) framework. We focus on answering the most common types of questions, i.e., simple questions, in which each question could be answered by the machine straightforwardly if its single head entity and single predicate are correctly identified. To answer a simple question, instead of inferring its head entity and predicate directly, KEQA targets at jointly recovering the question's head entity, predicate, and tail entity representations in the KG embedding spaces. Based on a carefully-designed joint distance metric, the three learned vectors' closest fact in the KG is returned as the answer. Experiments on a widely-adopted benchmark demonstrate that the proposed KEQA outperforms the state-of-the-art QA-KG methods.},
booktitle = {Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining},
pages = {105-–113},
numpages = {9},
keywords = {question answering, deep learning, knowledge graph embedding},
location = {Melbourne, Australia}
}

@inproceedings{10.1145/3132847.3132977,
author = {Zheng, Weiguo and Cheng, Hong and Zou, Lei and Yu, Jeffrey Xu and Zhao, Kangfei},
title = {Natural Language Question/Answering: Let Users Talk With The Knowledge Graph},
year = {2017},
isbn = {9781450349185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The ever-increasing knowledge graphs impose an urgent demand of providing effective and easy-to-use query techniques for end users. Structured query languages, such as SPARQL, offer a powerful expression ability to query RDF datasets. However, they are difficult to use. Keywords are simple but have a very limited expression ability. Natural language question (NLQ) is promising on querying knowledge graphs. A huge challenge is how to understand the question clearly so as to translate the unstructured question into a structured query. In this paper, we present a data + oracle approach to answer NLQs over knowledge graphs. We let users verify the ambiguities during the query understanding. To reduce the interaction cost, we formalize an interaction problem and design an efficient strategy to solve the problem. We also propose a query prefetch technique by exploiting the latency in the interactions with users. Extensive experiments over the QALD dataset demonstrate that our proposed approach is effective as it outperforms state-of-the-art methods in terms of both precision and recall.},
booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
pages = {217-–226},
numpages = {10},
keywords = {interactive query, natural language question and answering, knowledge graph},
location = {Singapore, Singapore}
}

@article{ji2020survey,
  author={Ji, Shaoxiong and Pan, Shirui and Cambria, Erik and Marttinen, Pekka and Yu, Philip S.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Survey on Knowledge Graphs: Representation, Acquisition, and Applications}, 
  year={2022},
  volume={33},
  number={2},
  pages={494--514},
  doi={10.1109/TNNLS.2021.3070843}}

@inproceedings{10.5555/2999792.2999923,
author = {Bordes, Antoine and Usunier, Nicolas and Garcia-Dur\'{a}n, Alberto and Weston, Jason and Yakhnenko, Oksana},
title = {Translating Embeddings for Modeling Multi-Relational Data},
year = {2013},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.},
booktitle = {Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2},
pages = {2787-–2795},
numpages = {9},
location = {Lake Tahoe, Nevada}
}

@inproceedings{10.5555/2893873.2894046,
author = {Wang, Zhen and Zhang, Jianwen and Feng, Jianlin and Chen, Zheng},
title = {Knowledge Graph Embedding by Translating on Hyperplanes},
year = {2014},
publisher = {AAAI Press},
abstract = {We deal with embedding a large scale knowledge graph composed of entities and relations into a continuous vector space. TransE is a promising method proposed recently, which is very efficient while achieving state-of-the-art predictive performance. We discuss some mapping properties of relations which should be considered in embedding, such as reflexive, one-to-many, many-to-one, and many-to-many. We note that TransE does not do well in dealing with these properties. Some complex models are capable of preserving these mapping properties but sacrifice efficiency in the process. To make a good trade-off between model capacity and efficiency, in this paper we propose TransH which models a relation as a hyperplane together with a translation operation on it. In this way, we can well preserve the above mapping properties of relations with almost the same model complexity of TransE. Additionally, as a practical knowledge graph is often far from completed, how to construct negative examples to reduce false negative labels in training is very important. Utilizing the one-to-many/many-to-one mapping property of a relation, we propose a simple trick to reduce the possibility of false negative labeling. We conduct extensive experiments on link prediction, triplet classification and fact extraction on benchmark datasets like WordNet and Freebase. Experiments show TransH delivers significant improvements over TransE on predictive accuracy with comparable capability to scale up.},
booktitle = {Proceedings of the Twenty-Eighth AAAI Conference on Artificial Intelligence},
pages = {1112–-1119},
numpages = {8},
address = {Qu\'{e}bec City, Qu\'{e}bec, Canada}
}

@inproceedings{Wang_Wang_Xu_He_Cao_Chua_2019, 
title={Explainable Reasoning over Knowledge Graphs for Recommendation},   
booktitle={Proceedings of the Thirty-Sixth AAAI Conference on Artificial Intelligence}, 
author={Wang, Xiang and Wang, Dingxian and Xu, Canran and He, Xiangnan and Cao, Yixin and Chua, Tat-Seng}, 
year={2019}, 
address = {Online},
publisher = {AAAI Press},
pages={5329--5336} 
}

@article{10.1145/2899005,
author = {Noia, Tommaso Di and Ostuni, Vito Claudio and Tomeo, Paolo and Sciascio, Eugenio Di},
title = {{SP}rank: Semantic Path-Based Ranking for Top-{N} Recommendations Using Linked Open Data},
year = {2016},
issue_date = {October 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
pages={1--34},
issn = {2157-6904},
abstract = {In most real-world scenarios, the ultimate goal of recommender system applications is to suggest a short ranked list of items, namely top-N recommendations, that will appeal to the end user. Often, the problem of computing top-N recommendations is mainly tackled with a two-step approach. The system focuses first on predicting the unknown ratings, which are eventually used to generate a ranked recommendation list. Actually, the top-N recommendation task can be directly seen as a ranking problem where the main goal is not to accurately predict ratings but to directly find the best-ranked list of items to recommend. In this article we present SPrank, a novel hybrid recommendation algorithm able to compute top-N recommendations exploiting freely available knowledge in the Web of Data. In particular, we employ DBpedia, a well-known encyclopedic knowledge base in the Linked Open Data cloud, to extract semantic path-based features and to eventually compute top-N recommendations in a learning-to-rank fashion. Experiments with three datasets related to different domains (books, music, and movies) prove the effectiveness of our approach compared to state-of-the-art recommendation algorithms.},
journal = {ACM Transactions on Intelligent Systems and Technology},
month = sep,
articleno = {9},
numpages = {34},
keywords = {hybrid recommender systems, DBpedia, Learning to rank}
}

@inproceedings{bhargava2019collaborative,
  title={Collaborative methodologies for pattern evaluation for web personalization using Semantic Web Mining},
  author={Bhargava, Ritu and Kumar, Abhishek and Gupta, Sweta},
  booktitle={2019 International Conference on Smart Systems and Inventive Technology},
  pages={852--855},
  address = "Tirunelveli, India",
  publisher={IEEE},
  year={2019}
}

@article{lehmann2015dbpedia,
  title={{DB}pedia - a large-scale, multilingual knowledge base extracted from wikipedia},
  author={Lehmann, Jens and Isele, Robert and Jakob, Max and Jentzsch, Anja and Kontokostas, Dimitris and Mendes, Pablo N and Hellmann, Sebastian and Morsey, Mohamed and Van Kleef, Patrick and Auer, S{\"o}ren and others},
  journal={Semantic Web},
  volume={6},
  number={2},
  pages={167--195},
  year={2015},
  publisher={IOS Press}
}

@article {PMID:32032717,
	Title = {A neural network-based joint learning approach for biomedical entity and relation extraction from biomedical literature},
	Author = {Luo, Ling and Yang, Zhihao and Cao, Mingyu and Wang, Lei and Zhang, Yin and Lin, Hongfei},
	DOI = {10.1016/j.jbi.2020.103384},
	Volume = {103},
	Year = {2020},
	Journal = {Journal of Biomedical Informatics},
	ISSN = {1532-0464},
	Pages = {1--8},
	Abstract = {Recently joint modeling methods of entity and relation exhibit more promising results than traditional pipelined methods in general domain. However, they are inappropriate for the biomedical domain due to numerous overlapping relations in biomedical text. To alleviate the problem, we propose a neural network-based joint learning approach for biomedical entity and relation extraction. In this approach, a novel tagging scheme that takes into account overlapping relations is proposed. Then the Att-BiLSTM-CRF model is built to jointly extract the entities and their relations with our extraction rules. Moreover, the contextualized ELMo representations pre-trained on biomedical text are used to further improve the performance. Experimental results on biomedical corpora show that our method can significantly improve the performance of overlapping relation extraction and achieves the state-of-the-art performance.},
	URL = {https://doi.org/10.1016/j.jbi.2020.103384},
}

@article{huang2020biomedical,
  title={Biomedical named entity recognition and linking datasets: survey and our recent development},
  author={Huang, Ming-Siang and Lai, Po-Ting and Lin, Pei-Yen and You, Yu-Ting and Tsai, Richard Tzong-Han and Hsu, Wen-Lian},
  journal={Briefings in Bioinformatics},
  volume={21},
  number={6},
  pages={2219--2238},
  year={2020},
  publisher={Oxford University Press}
}

@ARTICLE{9086146,  author={Hasan, S.M.Shamimul and Rivera, Donna and Wu, Xiao-Cheng and Durbin, Eric B. and Christian, J. Blair and Tourassi, Georgia},  journal={IEEE Journal of Biomedical and Health Informatics},   title={Knowledge Graph-Enabled Cancer Data Analytics},   year={2020},  volume={24},  number={7},  pages={1952--1967},  doi={10.1109/JBHI.2020.2990797}}

@article{HOLZINGER202128,
title = {Towards multi-modal causability with Graph Neural Networks enabling information fusion for explainable {AI}},
journal = {Information Fusion},
volume = {71},
pages = {28--37},
year = {2021},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521000142},
author = {Andreas Holzinger and Bernd Malle and Anna Saranti and Bastian Pfeifer},
keywords = {Information fusion, Explainable AI, xAI, Graph Neural Networks, Multi-modal causability, Knowledge graphs, Counterfactuals},
abstract = {AI is remarkably successful and outperforms human experts in certain tasks, even in complex domains such as medicine. Humans on the other hand are experts at multi-modal thinking and can embed new inputs almost instantly into a conceptual knowledge space shaped by experience. In many fields the aim is to build systems capable of explaining themselves, engaging in interactive what-if questions. Such questions, called counterfactuals, are becoming important in the rising field of explainable AI (xAI). Our central hypothesis is that using conceptual knowledge as a guiding model of reality will help to train more explainable, more robust and less biased machine learning models, ideally able to learn from fewer data. One important aspect in the medical domain is that various modalities contribute to one single result. Our main question is “How can we construct a multi-modal feature representation space (spanning images, text, genomics data) using knowledge bases as an initial connector for the development of novel explanation interface techniques?”. In this paper we argue for using Graph Neural Networks as a method-of-choice, enabling information fusion for multi-modal causability (causability – not to confuse with causality – is the measurable extent to which an explanation to a human expert achieves a specified level of causal understanding). The aim of this paper is to motivate the international xAI community to further work into the fields of multi-modal embeddings and interactive explainability, to lay the foundations for effective future human–AI interfaces. We emphasize that Graph Neural Networks play a major role for multi-modal causability, since causal links between features can be defined directly using graph structures.}
}

@article{funk2014large,
  title={Large-scale biomedical concept recognition: an evaluation of current automatic annotators and their parameters},
  author={Funk, Christopher and Baumgartner, William and Garcia, Benjamin and Roeder, Christophe and Bada, Michael and Cohen, K Bretonnel and Hunter, Lawrence E and Verspoor, Karin},
  journal={BMC Bioinformatics},
  volume={15},
  number={1},
  pages={1--29},
  year={2014},
  publisher={Springer}
}

% CHAPTER 5

@article{li2016biocreative,
  title={Bio{C}reative {V CDR} task corpus: a resource for chemical disease relation extraction},
  author={Li, Jiao and Sun, Yueping and Johnson, Robin J and Sciaky, Daniela and Wei, Chih-Hsuan and Leaman, Robert and Davis, Allan Peter and Mattingly, Carolyn J and Wiegers, Thomas C and Lu, Zhiyong},
  journal={Database},
  volume={2016},
  year={2016},
  pages={1--10},
  publisher={Oxford Academic}
}

@article{sousa2020hybrid,
  title={A hybrid approach toward biomedical relation extraction training corpora: combining distant supervision with crowdsourcing},
  author={Sousa, Diana and Lamurias, Andre and Couto, Francisco M},
  journal={Database},
  volume={2020},
  pages={1--15},
  year={2020},
  publisher={Oxford Academic}
}

@article{segura2014lessons,
  title={Lessons learnt from the DDIExtraction-2013 shared task},
  author={Segura-Bedmar, Isabel and Mart{\'\i}nez, Paloma and Herrero-Zazo, Mar{\'\i}a},
  journal={Journal of Biomedical Informatics},
  volume={51},
  pages={152--164},
  year={2014},
  publisher={Elsevier}
}

@article{hu2021survey,
  title={A survey on computational models for predicting protein--protein interactions},
  author={Hu, Lun and Wang, Xiaojuan and Huang, Yu-An and Hu, Pengwei and You, Zhu-Hong},
  journal={Briefings in Bioinformatics},
  volume={22},
  number={5},
  pages={1--36},
  year={2021},
  publisher={Oxford University Press}
}

@inproceedings{song2019leveraging,
  title={Leveraging Dependency Forest for Neural Medical Relation Extraction},
  author={Song, Linfeng and Zhang, Yue and Gildea, Daniel and Yu, Mo and Wang, Zhiguo and Su, Jinsong},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing},
  address={Hong Kong, China},
  publisher={Association for Computational Linguistics},
  pages={208--218},
  year={2019}
}

@article{sousa2022biomedical,
  title={Biomedical Relation Extraction with Knowledge Graph-based Recommendations},
  author={Sousa, Diana and Couto, Francisco M},
  journal={IEEE Journal of Biomedical and Health Informatics},
  year={2022},
  volume={26},
  number={8},
  pages={4207--4217},
  publisher={IEEE}
}

@article{bodenreider2004unified,
  title={The unified medical language system ({UMLS}): integrating biomedical terminology},
  author={Bodenreider, Olivier},
  journal={Nucleic Acids Research},
  volume={32},
  number={suppl\_1},
  pages={267--270},
  year={2004},
  publisher={Oxford University Press}
}

@article{degtyarenko2007chebi,
  title={Ch{EBI}: a database and ontology for chemical entities of biological interest},
  author={Degtyarenko, Kirill and De Matos, Paula and Ennis, Marcus and Hastings, Janna and Zbinden, Martin and McNaught, Alan and Alc{\'a}ntara, Rafael and Darsow, Michael and Guedj, Micka{\"e}l and Ashburner, Michael},
  journal={Nucleic Acids Research},
  volume={36},
  number={suppl\_1},
  pages={344--350},
  year={2007},
  publisher={Oxford University Press}
}

@article{schriml2022human,
  title={The human disease ontology 2022 update},
  author={Schriml, Lynn M and Munro, James B and Schor, Mike and Olley, Dustin and McCracken, Carrie and Felix, Victor and Baron, J Allen and Jackson, Rebecca and Bello, Susan M and Bearer, Cynthia and others},
  journal={Nucleic Acids Research},
  volume={50},
  number={1},
  pages={1255--1261},
  year={2022},
  publisher={Oxford University Press}
}

@article{kohler2021human,
  title={The human phenotype ontology in 2021},
  author={K{\"o}hler, Sebastian and Gargano, Michael and Matentzoglu, Nicolas and Carmody, Leigh C and Lewis-Smith, David and Vasilevsky, Nicole A and Danis, Daniel and Balagura, Ganna and Baynam, Gareth and Brower, Amy M and others},
  journal={Nucleic Acids Research},
  volume={49},
  number={1},
  pages={1207--1217},
  year={2021},
  publisher={Oxford University Press}
}

@article{gene2019gene,
  title={The gene ontology resource: 20 years and still {GO}ing strong},
  author={Gene Ontology Consortium},
  journal={Nucleic Acids Research},
  volume={47},
  number={1},
  pages={330--338},
  year={2019},
  publisher={Oxford University Press}
}

@inproceedings{liu2020k,
  title={K-{BERT}: Enabling language representation with knowledge graph},
  author={Liu, Weijie and Zhou, Peng and Zhao, Zhe and Wang, Zhiruo and Ju, Qi and Deng, Haotang and Wang, Ping},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  address={New York, NY, USA},
  pages={2901--2908},
  publisher={Association for the Advancement of Artificial Intelligence},
  year={2020}
}

@inproceedings{hao2020enhancing,
    title = "Enhancing Clinical {BERT} Embedding using a Biomedical Knowledge Base",
    author = "Hao, Boran  and
      Zhu, Henghui  and
      Paschalidis, Ioannis",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.57",
    doi = "10.18653/v1/2020.coling-main.57",
    pages = "657--661",
    abstract = "Domain knowledge is important for building Natural Language Processing (NLP) systems for low-resource settings, such as in the clinical domain. In this paper, a novel joint training method is introduced for adding knowledge base information from the Unified Medical Language System (UMLS) into language model pre-training for some clinical domain corpus. We show that in three different downstream clinical NLP tasks, our pre-trained language model outperforms the corresponding model with no knowledge base information and other state-of-the-art models. Specifically, in a natural language inference task applied to clinical texts, our knowledge base pre-training approach improves accuracy by up to 1.7{\%}, whereas in clinical name entity recognition tasks, the F1-score improves by up to 1.0{\%}. The pre-trained models are available at https://github.com/noc-lab/clinical-kb-bert.",
}

@article{do2022developing,
  title={Developing a {BERT} based triple classification model using knowledge graph embedding for question answering system},
  author={Do, Phuc and Phan, Truong HV},
  journal={Applied Intelligence},
  volume={52},
  number={1},
  pages={636--651},
  year={2022},
  publisher={Springer}
}

@article{ruas2022nilinker,
  title={{NILINKER}: Attention-based approach to {NIL} Entity Linking},
  author={Ruas, Pedro and Couto, Francisco M},
  journal={Journal of Biomedical Informatics},
  volume={132},
  pages={1--12},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{zhao2019uer,
    title = "{UER}: An Open-Source Toolkit for Pre-training Models",
    author = "Zhao, Zhe  and
      Chen, Hui  and
      Zhang, Jinbin  and
      Zhao, Xin  and
      Liu, Tao  and
      Lu, Wei  and
      Chen, Xi  and
      Deng, Haotang  and
      Ju, Qi  and
      Du, Xiaoyong",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-3041",
    doi = "10.18653/v1/D19-3041",
    pages = "241--246",
    abstract = "Existing works, including ELMO and BERT, have revealed the importance of pre-training for NLP tasks. While there does not exist a single pre-training model that works best in all cases, it is of necessity to develop a framework that is able to deploy various pre-training models efficiently. For this purpose, we propose an assemble-on-demand pre-training toolkit, namely Universal Encoder Representations (UER). UER is loosely coupled, and encapsulated with rich modules. By assembling modules on demand, users can either reproduce a state-of-the-art pre-training model or develop a pre-training model that remains unexplored. With UER, we have built a model zoo, which contains pre-trained models based on different corpora, encoders, and targets (objectives). With proper pre-trained models, we could achieve new state-of-the-art results on a range of downstream datasets.",
}

@article{nasar2021named,
  title={Named entity recognition and relation extraction: State-of-the-art},
  author={Nasar, Zara and Jaffry, Syed Waqar and Malik, Muhammad Kamran},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={1},
  pages={1--39},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{abdelkader2021machine,
  title={Machine learning approaches to retrieve high-quality, clinically relevant evidence from the biomedical literature: systematic review},
  author={Abdelkader, Wael and Navarro, Tamara and Parrish, Rick and Cotoi, Chris and Germini, Federico and Iorio, Alfonso and Haynes, R Brian and Lokker, Cynthia and others},
  journal={JMIR Medical Informatics},
  volume={9},
  number={9},
  pages={1--14},
  year={2021},
  publisher={JMIR Publications Inc., Toronto, Canada}
}

@book{dash2020deep,
  title={Deep learning techniques for biomedical and health informatics},
  author={Dash, Sujata and Acharya, Biswa Ranjan and Mittal, Mamta and Abraham, Ajith and Kelemen, Arpad},
  year={2020},
  publisher={Springer}
}

@article{houssein2021machine,
  title={Machine learning techniques for biomedical natural language processing: a comprehensive review},
  author={Houssein, Essam H and Mohamed, Rehab E and Ali, Abdelmgeid A},
  journal={IEEE Access},
  year={2021},
  volume={9},
  number={},
  pages={140628--140653},
  publisher={IEEE}
}

@article{kilicoglu2020broad,
  title={Broad-coverage biomedical relation extraction with {S}em{R}ep},
  author={Kilicoglu, Halil and Rosemblat, Graciela and Fiszman, Marcelo and Shin, Dongwook},
  journal={BMC Bioinformatics},
  volume={21},
  number={1},
  pages={1--28},
  year={2020},
  publisher={Springer}
}

@article{kim2006biocontrasts,
  title={Bio{C}ontrasts: extracting and exploiting protein--protein contrastive relations from biomedical literature},
  author={Kim, Jung-Jae and Zhang, Zhuo and Park, Jong C and Ng, See-Kiong},
  journal={Bioinformatics},
  volume={22},
  number={5},
  pages={597--605},
  year={2006},
  publisher={Oxford University Press}
}

@article{zhou2014biomedical,
  title={Biomedical relation extraction: from binary to complex},
  author={Zhou, Deyu and Zhong, Dayou and He, Yulan},
  journal={Computational and mathematical methods in medicine},
  volume={2014},
  publisher={Hindawi}
}

@article{rinaldi2007mining,
  title={Mining of relations between proteins over biomedical scientific literature using a deep-linguistic approach},
  author={Rinaldi, Fabio and Schneider, Gerold and Kaljurand, Kaarel and Hess, Michael and Andronis, Christos and Konstandi, Ourania and Persidis, Andreas},
  journal={Artificial Intelligence in Medicine},
  volume={39},
  number={2},
  pages={127--136},
  year={2007},
  publisher={Elsevier}
}

@inproceedings{devlin2019bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@article{gu2021domain,
  title={Domain-specific language model pretraining for biomedical natural language processing},
  author={Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal={ACM Transactions on Computing for Healthcare (HEALTH)},
  volume={3},
  number={1},
  pages={1--23},
  year={2021},
  publisher={ACM New York, NY}
}

@inproceedings{scibert,
    title = "{S}ci{BERT}: A Pretrained Language Model for Scientific Text",
    author = "Beltagy, Iz  and
      Lo, Kyle  and
      Cohan, Arman",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D19-1371",
    doi = "10.18653/v1/D19-1371",
    pages = "3615--3620",
    abstract = "Obtaining large-scale annotated data for NLP tasks in the scientific domain is challenging and expensive. We release SciBERT, a pretrained language model based on BERT (Devlin et. al., 2018) to address the lack of high-quality, large-scale labeled scientific data. SciBERT leverages unsupervised pretraining on a large multi-domain corpus of scientific publications to improve performance on downstream scientific NLP tasks. We evaluate on a suite of tasks including sequence tagging, sentence classification and dependency parsing, with datasets from a variety of scientific domains. We demonstrate statistically significant improvements over BERT and achieve new state-of-the-art results on several of these tasks. The code and pretrained models are available at https://github.com/allenai/scibert/.",
}

% CHAPTER 6

@article{herrero2013ddi,
  title={The {DDI} corpus: An annotated corpus with pharmacological substances and drug--drug interactions},
  author={Herrero-Zazo, Mar{\'\i}a and Segura-Bedmar, Isabel and Mart{\'\i}nez, Paloma and Declerck, Thierry},
  journal={Journal of Biomedical Informatics},
  volume={46},
  number={5},
  pages={914--920},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{sousa2019silver,
  title={A Silver Standard Corpus of Human Phenotype-Gene Relations},
  author={Sousa, Diana and Lamurias, Andre and Couto, Francisco M},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={1487--1492},
  publisher={Association for Computational Linguistics},
  address={Minneapolis, Minnesota},
  year={2019}
}

@inproceedings{narayan2018ranking,
    title = "Ranking Sentences for Extractive Summarization with Reinforcement Learning",
    author = "Narayan, Shashi  and
      Cohen, Shay B.  and
      Lapata, Mirella",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1158",
    doi = "10.18653/v1/N18-1158",
    pages = "1747--1759",
    abstract = "Single document summarization is the task of producing a shorter version of a document while preserving its principal information content. In this paper we conceptualize extractive summarization as a sentence ranking task and propose a novel training algorithm which globally optimizes the ROUGE evaluation metric through a reinforcement learning objective. We use our algorithm to train a neural summarization model on the CNN and DailyMail datasets and demonstrate experimentally that it outperforms state-of-the-art extractive and abstractive systems when evaluated automatically and by humans.",
}

@inproceedings{liu2016effective,
  title={Effective crowd annotation for relation extraction},
  author={Liu, Angli and Soderland, Stephen and Bragg, Jonathan and Lin, Christopher H and Ling, Xiao and Weld, Daniel S},
  booktitle={Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={897--906},
  address={San Diego, CA, USA},
  publisher={Association for Computational Linguistics},
  year={2016}
}

@inproceedings{callison2010creating,
  title={Creating speech and language data with amazon’s mechanical turk},
  author={Callison-Burch, Chris and Dredze, Mark},
  booktitle={Proceedings of the NAACL HLT 2010 workshop on creating speech and language data with Amazon’s Mechanical Turk},
  pages={1--12},
  publisher = "Association for Computational Linguistics",
  address = "Los Angeles, CA, USA",
  year={2010}
}
    
@inproceedings{yetisgen2010preliminary,
  title={Preliminary experiments with Amazon’s mechanical turk for annotating medical named entities},
  author={Yetisgen-Yildiz, Meliha and Solti, Imre and Xia, Fei and Halgrim, Scott},
  booktitle={Proceedings of the NAACL HLT 2010 workshop on creating speech and language data with Amazon’s Mechanical Turk},
  pages={180--183},
  address={Los Angeles, CA, USA},
  publisher={Association for Computational Linguistics},
  year={2010}
}

@article{wang2013perspectives,
  title={Perspectives on crowdsourcing annotations for natural language processing},
  author={Wang, Aobo and Hoang, Cong Duy Vu and Kan, Min-Yen},
  journal={Language Resources and Evaluation},
  volume={47},
  number={1},
  pages={9--31},
  year={2013},
  publisher={Springer}
}

@inproceedings{feyisetan2015towards,
  title={Towards hybrid NER: A study of content and crowdsourcing-related performance factors},
  author={Feyisetan, Oluwaseyi and Luczak-Roesch, Markus and Simperl, Elena and Tinati, Ramine and Shadbolt, Nigel},
  booktitle={European Semantic Web Conference},
  pages={525--540},
  year={2015},
  address={Portoroz, Slovenia},
  organization={Springer}
}

@article{mortensen2018comparing,
  title={Comparing Amazon’s Mechanical Turk platform to conventional data collection methods in the health and medical research literature},
  author={Mortensen, Karoline and Hughes, Taylor L},
  journal={Journal of General Internal Medicine},
  volume={33},
  number={4},
  pages={533--538},
  year={2018},
  publisher={Springer}
}

@article{fort2011amazon,
  title={Amazon mechanical turk: Gold mine or coal mine?},
  author={Fort, Kar{\"e}n and Adda, Gilles and Cohen, K Bretonnel},
  journal={Computational Linguistics},
  volume={37},
  number={2},
  pages={413--420},
  year={2011},
  publisher={MIT Press}
}

@article{paolacci2014inside,
  title={Inside the Turk: Understanding Mechanical Turk as a participant pool},
  author={Paolacci, Gabriele and Chandler, Jesse},
  journal={Current Directions in Psychological Science},
  volume={23},
  number={3},
  pages={184--188},
  year={2014},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{mchugh2012interrater,
  title={Interrater reliability: the kappa statistic},
  author={McHugh, Mary L},
  journal={Biochemia Medica},
  volume={22},
  number={3},
  pages={276--282},
  year={2012},
  publisher={Medicinska naklada}
}

@article{krippendorff2011computing,
  title={Computing Krippendorff's alpha-reliability},
  author={Krippendorff, Klaus},
  pages={1--12},
  year={2011}
}

@article{lee2020biobert,
  title={Bio{BERT}: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020},
  publisher={Oxford University Press}
}

@article{paolacci2010running,
  title={Running experiments on amazon mechanical turk},
  author={Paolacci, Gabriele and Chandler, Jesse and Ipeirotis, Panagiotis G},
  journal={Judgment and Decision Making},
  volume={5},
  number={5},
  pages={411--419},
  year={2010}
}

@article{zapf2016measuring,
  title={Measuring inter-rater reliability for nominal data--which coefficients and confidence intervals are appropriate?},
  author={Zapf, Antonia and Castell, Stefanie and Morawietz, Lars and Karch, Andr{\'e}},
  journal={BMC Medical Research Methodology},
  volume={16},
  number={1},
  pages={1--10},
  year={2016},
  publisher={Springer}
}

@inproceedings{chen2018efficient,
  title={Efficient road lane marking detection with deep learning},
  author={Chen, Ping-Rong and Lo, Shao-Yuan and Hang, Hsueh-Ming and Chan, Sheng-Wei and Lin, Jing-Jhih},
  booktitle={2018 IEEE 23rd International Conference on Digital Signal Processing},
  pages={1--5},
  year={2018},
  address={Shanghai, China},
  organization={IEEE}
}

@inproceedings{gracca2018unbabel,
  title={Unbabel: How to combine AI with the crowd to scale professional-quality translation},
  author={Gra{\c{c}}a, Jo{\~a}o},
  booktitle={Proceedings of the AMTA 2018 Workshop on Translation Quality Estimation and Automatic Post-Editing},
  pages={41--85},
  publisher={Association for Machine Translation in the Americas},
  address={Boston, MA, USA},
  year={2018}
}

@article{kleffner2017foldit,
  title={Foldit Standalone: a video game-derived protein structure manipulation interface using Rosetta},
  author={Kleffner, Robert and Flatten, Jeff and Leaver-Fay, Andrew and Baker, David and Siegel, Justin B and Khatib, Firas and Cooper, Seth},
  journal={Bioinformatics},
  volume={33},
  number={17},
  pages={2765--2767},
  year={2017},
  publisher={Oxford University Press}
}

% CHAPTER 7

@proceedings{nlp-covid19-2020-nlp,
    title = "Proceedings of the 1st Workshop on {NLP} for {COVID-19} at {ACL} 2020",
    editor = "Verspoor, Karin  and
      Cohen, Kevin Bretonnel  and
      Dredze, Mark  and
      Ferrara, Emilio  and
      May, Jonathan  and
      Munro, Robert  and
      Paris, Cecile  and
      Wallace, Byron",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.nlpcovid19-acl.0",
}

@inproceedings{wang-etal-2020-cord,
    title = "{CORD-19}: The {COVID-19} Open Research Dataset",
    author = "Wang, Lucy Lu  and
      Lo, Kyle  and
      Chandrasekhar, Yoganand  and
      Reas, Russell  and
      Yang, Jiangjiang  and
      Burdick, Doug  and
      Eide, Darrin  and
      Funk, Kathryn  and
      Katsis, Yannis  and
      Kinney, Rodney Michael  and
      Li, Yunyao  and
      Liu, Ziyang  and
      Merrill, William  and
      Mooney, Paul  and
      Murdick, Dewey A.  and
      Rishi, Devvret  and
      Sheehan, Jerry  and
      Shen, Zhihong  and
      Stilson, Brandon  and
      Wade, Alex D.  and
      Wang, Kuansan  and
      Wang, Nancy Xin Ru  and
      Wilhelm, Christopher  and
      Xie, Boya  and
      Raymond, Douglas M.  and
      Weld, Daniel S.  and
      Etzioni, Oren  and
      Kohlmeier, Sebastian",
    booktitle = "Proceedings of the 1st Workshop on {NLP} for {COVID-19} at {ACL} 2020",
    month = jul,
    year = "2020",
    address = "Online",
    pages={1--12},
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.nlpcovid19-acl.1",
    abstract = "The COVID-19 Open Research Dataset (CORD-19) is a growing resource of scientific papers on COVID-19 and related historical coronavirus research. CORD-19 is designed to facilitate the development of text mining and information retrieval systems over its rich collection of metadata and structured full text papers. Since its release, CORD-19 has been downloaded over 200K times and has served as the basis of many COVID-19 text mining and discovery systems. In this article, we describe the mechanics of dataset construction, highlighting challenges and key design decisions, provide an overview of how CORD-19 has been used, and describe several shared tasks built around the dataset. We hope this resource will continue to bring together the computing community, biomedical experts, and policy makers in the search for effective treatments and management policies for COVID-19.",
}

@article{kim2020editor,
  title={Editor’s introduction to the special issue of the 6th Biomedical Linked Annotation Hackathon (BLAH6)},
  author={Kim, Jin-Dong and Cohen, Kevin Bretonnel and Rinaldi, Fabio and Lu, Zhiyong and Collier, Nigel and Park, Hyun-Seok},
  journal={Genomics \& Informatics},
  volume={18},
  number={2},
  pages={1--2},
  year={2020},
  publisher={Korea Genome Organization}
}

@article{hirschman2005overview,
  title={Overview of {BioCreAtIvE}: critical assessment of information extraction for biology},
  author={Hirschman, Lynette and Yeh, Alexander and Blaschke, Christian and Valencia, Alfonso},
  journal={BMC Bioinformatics},
  volume={6},
  number={1},
  pages={S1},
  year={2005},
  publisher={BioMed Central}
}

@article{kim2021editor,
  title={Editor’s introduction to the special section on the 7th Biomedical Linked Annotation Hackathon (BLAH7)},
  author={Kim, Jin-Dong and Cohen, Kevin Bretonnel and Rinaldi, Fabio and Lu, Zhiyong and Park, Hyun-Seok},
  journal={Genomics \& Informatics},
  volume={19},
  number={3},
  pages={1--2},
  year={2021},
  publisher={Korea Genome Organization}
}

@inproceedings{jullien-2023-nli4ct,
    title = "Sem{E}val-2023 Task 7: Multi-Evidence Natural Language Inference for Clinical Trial Data",
    author = "Jullien, Mael and Valentino, Marco and Frost, Hannah and O'Regan, Paul and Landers, Donal and Freitas, André",
    booktitle = "Proceedings of the 17th International Workshop on Semantic Evaluation",
    year = "2023",
    address={Toronto, Canada},
    pages={1--11},
    publisher={Association for Computational Linguistics}
}

% CHAPTER 8

@inproceedings{strubell2019energy,
  title={Energy and Policy Considerations for Deep Learning in {NLP}},
  author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={3645--3650},
  address={Florence, Italy},
  publisher={Association for Computational Linguistics},
  year={2019}
}
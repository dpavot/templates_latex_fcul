\hypertarget{3}{}

\chapter{A Silver Standard Corpus of Phenotype-Gene Relations}

\rhead{A Silver Standard Corpus of Phenotype-Gene Relations}
\lhead{Chapter 3}

\vspace{-1.6cm}

% Gray Line
\begingroup
\color{gray}
\par\noindent\rule{\textwidth}{0.4pt}
\endgroup

The main problem of the systems that perform biomedical Relation Extraction (RE) is a lack of specific high quality annotated corpora, a gold standard corpus, mostly because this task requires not only a considerable amount of manual effort but also specific expertise that is not widely available. A solution to these limitations is to generate the corpus in a fully automated manner, creating a silver standard corpus.

To extract human phenotype-gene relations, both entities, human phenotypes, and genes, have to be recognized. With genes, as a result of lexical features being relatively regular, many systems can successfully identify them in text \citep{BANNER}. Even though Named-Entity Recognition (NER) research has significantly improved in the last years, human phenotype identification is still a complex task, only tackled by a handful of systems \citep{IHP}.

Thus, to generate a silver standard for human phenotype-gene relation extraction, we need a pipeline that performs: 

\begin{itemize}
\item{\textbf{NER} to recognize genes and human phenotype entities.} 
\item{\textbf{RE} to classify a relation between human phenotype and gene entities.}
\end{itemize}

There is no corpus available specific to human phenotype-gene relations. This chapter will present the work developed to overcome this issue, by creating a large and versatile silver standard corpus, able to be applied to Machine Learning (ML) tools. To assess the quality of the Phenotype-Gene Relations (PGR) corpus, eight curators manually evaluated a subset of the PGR.

% ------------------------------> METHODS

\section{Methods}

The Human Phenotype Ontology (HPO) \citep{HPO} is responsible for providing a standardized vocabulary of phenotypic abnormalities encountered in human diseases. The developers of the HPO also made available a knowledge base that links these phenotypic abnormalities to genes. These phenotype-gene relations are regularly extracted from texts in the Online Mendelian Inheritance in Man (OMIM) and  Orphanet (ORPHA) databases, where all phenotype terms associated with any disease that is related with a gene are assigned to that gene in the relations knowledge base. In this work, the relations knowledge base created by HPO was used as a gold standard for human phenotype-gene relations.

The first step was retrieving abstracts from PubMed, using the genes involved in phenotype-gene relations and \textit{homo sapiens} as keywords, and the Entrez Programming Utilities (E-utilities) web service\footnote{\url{https://www.ncbi.nlm.nih.gov/books/NBK25501/}}, retrieving one abstract per gene (Query 1)\footnote{Query 1, corresponds to the \textit{10/12/2018} release of PGR} (Example \hyperlink{ex3.1}{3.1}). 

Later, the keyword \textit{disease} and a filter for abstracts in English were added (Query 2)\footnote{Query 2, corresponds to the \textit{11/03/2019} release of PGR}.  Query 2 represents a more focused search of the type of abstracts to retrieve, such as abstracts regarding diseases, their associated phenotypes and genes.

For each gene, the system selected the most recent abstract (Query 1) the two most recent abstracts (Query 2).

\bigskip

% EXAMPLE 3.1

\hypertarget{ex3.1}{\textbf{Example 3.1}} PubMed query 1 result example.

\begin{itemize}

\item\textbf{Keywords:} \textit{NF2} and \textit{homo sapiens}
\item\textbf{Abstract Identifier:} 30194202
\item\textbf{Abstract Title:} Demographical Profile and Spectrum of Multiple Malignancies in Children and Adults with Neurocutaneous Disorders

\end{itemize}

% END EXAMPLE 3.1

The query searched by gene name and not human phenotype or the combination of both terms because this approach was the one that retrieved abstracts with the higher number of gene and human phenotype annotations, in the following NER and RE phases. The abstracts that did not check the conditions of being written in English, with a correct XML format and content, were removed. The final number of abstracts was 1712 for Query 1 and 2657 for Query 2 as presented in Table \ref{table:number_NER_DS}.

% TABLE 3.1

\begin{table}[!ht]
\renewcommand\arraystretch{1.2}
\small
\captionsetup{font=small}
\caption[Final Number of Abstracts, Entities, and Relations Extracted]{The final number of abstracts retrieved, number of phenotype and gene annotations extracted and the number of known, unknown and total of relations extracted between phenotype and genes, for Query 1 and 2.} 
\centering
\taburulecolor{black}
\newcolumntype{C}{ >{\centering\arraybackslash} m{1.8cm} }
\newcolumntype{D}{ >{\centering\arraybackslash} m{2cm} }
\newcolumntype{E}{ >{\centering\arraybackslash} m{2cm} }
\newcolumntype{U}{ >{\centering\arraybackslash} m{1.3cm} }
\begin{tabular}{|E|D|C|U|U|C|U|}
\hline
\multirow{2}{*}{\textbf{Query}} & \multirow{2}{*}{\textbf{Abstracts}} & \multicolumn{2}{c|}{\textbf{Annotations}} & \multicolumn{3}{c|}{\textbf{Relations}} \\
\cline{3-7}
& & \textbf{Phenotype} & \textbf{Gene} & \textbf{Known} & \textbf{Unknown} & \textbf{Total} \\
\hline\hline
\textbf{1} (10/12/2018) & 1712 & 5676 & 13835 & 1510 & 2773 & 4283 \\
\hline
\textbf{2} (11/03/2019) & 2657 & 9553 & 23786 & 2480 & 5483 & 7963 \\
\hline
\end{tabular}
\label{table:number_NER_DS}
\end{table}

% END TABLE 3.1

The next step was to use the Minimal Named-Entity Regonition (MER) tool \citep{MER} for the annotation of the genes and the IHP framework for the annotation of human phenotype terms.

% ----------------> GENE EXTRACTION

\subsection{Gene Extraction}

MER is a dictionary-based NER tool which given any lexicon or ontology (e.g., an OWL file) and an input text returns a list of recognized entities, their location, and links to their respective classes. 

To annotate genes with MER it is necessary to provide a file of gene names and their respective identifiers. To this end, the system used a list created by the HUGO Gene Nomenclature Committee (HGNC) at the European Bioinformatics Institute\footnote{\url{http://www.genenames.org/}}. The HGNC is responsible for approving unique symbols and names for human loci, including protein-coding genes, ncRNA genes, and pseudogenes, with the goal of promoting clear scientific communication. Considering that the goal was not only to map the genes to their names but also their Entrez Gene\footnote{\url{www.ncbi.nlm.nih.gov/gene/}} identifiers, the system used the API from MyGene\footnote{\url{http://mygene.info/}} with the keyword \textit{human} in species. The MyGene API provides several gene characteristics, including the confidence score for several possible genes that match the query. For this work, the choice was the Entrez Gene identifier with the higher confidence score. The first option was the Entrez Gene identifiers because of their widespread use in the biomedical research field. 

After corresponding all gene names to their respective identifiers, there were three genes that did not have identifiers (\textit{CXorf36}, \textit{OR4Q2}, and \textit{SCYGR9}). For the first two genes (\textit{CXorf36} and \textit{OR4Q2}), a simple search in Entrez Gene allowed us to match them to their identifiers. The last gene (\textit{SCYGR9}) did not have an Entrez Gene identifier, so the second option was to use the HGNC identifier for that gene instead. 

To the original gene list, were added gene synonyms using a synonyms list file\footnote{\url{https://github.com/macarthur-lab/gene_lists}} (expanding the original list almost 3-fold). These synonyms were matched to their identifiers and filtered according to their length to exclude one character length synonyms and avoid a fair amount of false positives. The number of genes in the original gene list was 19194, and by including their synonyms that number increased to 56670, representing a total gain of 37476 gene names.

At last, some missed gene annotations were identified using regular expressions. These missed gene annotations were next to forward/back slash and dashes characters (Example \hyperlink{ex3.1}{3.2}).

\bigskip

% EXAMPLE 3.2

\hypertarget{ex3.2}{\textbf{Example 3.2}} Missed gene annotation because of forward slash.
\begin{itemize}

\item\textbf{Gene:} \textit{BAX}
\item\textbf{Gene Identifier:} 581
\item\textbf{Abstract Identifier:} 30273005
\item\textbf{Sentence:} According to the morphological observations and DNA fragmentation assay, the MPS compound induced apoptosis in both cell lines, and also cause a significant increase in the expression of \textbf{Bax}/Bcl-2.

\end{itemize}

% END EXAMPLE 3.2

% ----------------> PHENOTYPE EXTRACTION

\subsection{Phenotype Extraction}

IHP is a Machine Learning-based  NER tool, specifically created to recognize HPO entities in unstructured text. It uses Stanford CoreNLP \citep{Manning2014} for text processing and applies Conditional Random Fields trained with a rich feature set, combined with hand-crafted validation rules and a dictionary to improve the recognition of phenotypes.

The IHP system was updated for the most recent version\footnote{\textit{09/10/2018} release} of the HPO ontology. The annotations that originated from the IHP system were matched to their HPO identifier. There were a total of 7478 annotations for Query 1 and 10973 annotations for Query 2 that did not match any HPO identifier. These annotations were gathered to be confirmed or discarded manually, as some of them are incorrectly identified entities but others are parts of adjacent entities that can be combined for an accurate annotation.

The MER system was not used for phenotype extraction mainly because a more efficient tool for this task was available without the limitations of a dictionary-based NER tool for complex terms as phenotypes are.

% -----------------> RELATION EXTRACTION
\subsection{Relation Extraction}

After filtering abstracts that did not have annotations of both types, gene, and phenotype, the total of abstracts for Query 1 was 1712 and for Query 2 was 2656 abstracts as presented in Table \ref{table:number_NER_DS}. The abstracts retrieved by Query 1 were not specific enough for human phenotype-gene relations and therefore about half of them did not contain entities from both types, which was addressed in Query 2, increasing from an average of 2.5 relations per abstract to about 3.0 relations per abstract.

Using a distant supervision approach, with the HPO knowledge base that links phenotypic abnormalities to genes, it was possible to classify a relation with \textit{Known} or \textit{Unknown}. The \textit{Known} relations are relations that are in the knowledge base and the \textit{Unknown} relations are relations that are not yet identified or that do not exist. For this end, the system extracted pairs of entities, of gene and human phenotype, by co-occurrence in the same sentence (Example \hyperlink{ex3.3}{3.3}). The final number of both \textit{Known} and \textit{Unknown} annotations is also presented in Table \ref{table:number_NER_DS}.

\bigskip

% EXAMPLE 3.3

\hypertarget{ex3.3}{\textbf{Example 3.3}} Relation extraction.

\begin{itemize}

\item\textbf{Abstract Identifier:} 23669344
\item\textbf{Sentence:} A homozygous mutation of \textbf{SERPINB6}, a gene encoding an intracellular protease inhibitor, has recently been associated with post-lingual, autosomal-recessive, nonsyndromic \textbf{hearing loss} in humans (DFNB91).
\item\textbf{Gene:} \textit{SERPINB6}
\item\textbf{Gene Identifier:} 5269
\item\textbf{Phenotype:} \textit{hearing loss}
\item\textbf{Phenotype Identifier:} HP\_0000365
\item\textbf{Relation:} \textbf{Known}

\end{itemize}

% END EXAMPLE 3.3

% ------------------------------> EVALUATION

\section{Evaluation}

To evaluate the quality of the classifier, 260 relations were randomly selected from Query 1 to be reviewed by eight curators (50 relations each, with an overlap of 20 relations). Curators were researchers work in the areas of Biology and Biochemistry. These curators had to evaluate the correctness of the classifier by attributing to each sentence one of the following options: \textit{C} (correct), \textit{I} (incorrect) or \textit{U} (uncertain). The \textit{U} option was given to identify cases of ambiguity and possible errors in the NER phase. A true positive (TP) was a \textit{Known} relation that was marked \textit{C} by the curator, a false positive (FP) was a \textit{Known} relation marked \textit{I}, a false negative (FN) was a \textit{Unknown} relation marked \textit{I} and a true negative (TN) was a \textit{Unknown} relation marked \textit{C}.

% ------------------------------>  RESULTS AND DISCUSSION

\section{Results and Discussion}

The final results are presented in Table \ref{table:relations}. The inter-curator agreement score, calculated from a total of 20 relations classified by eight curators, was 87.58\%. Besides the fact that there were a few incorrectly extracted relations due to errors in the NER phase, that were discarded, the inter-curator agreement is not higher due to the complexity of the sentences where the relations between entities were identified. Even with highly knowledgeable curators in the fields of Biology and Biochemistry, most of them expressed difficulties in deciding which mark to choose on complex sentences that did not necessarily imply a relation between the identified entities (Example \hyperlink{ex3.4}{3.4}). 

\bigskip

% EXAMPLE 3.4

\hypertarget{ex3.4}{\textbf{Example 3.4}} Relation marked with \textit{U} (Uncertain).
\begin{itemize}
\item\textbf{Abstract Identifier:} 27666346
\item\textbf{Sentence:} \textbf{FRMD4A} antibodies were used to probe 78 paraffin-embedded specimens of \textbf{tongue squamous cell carcinoma} and 15 normal tongue tissues, which served as controls.
\item\textbf{Mark:} \textbf{\textit{U}}
\end{itemize}

% END EXAMPLE 3.4

The most relevant metric for a silver standard corpus, directed towards ML tools, is precision. ML tools depend on correct examples to create effective models that can detect new cases, afterwards, being able to deal with small amounts of noise in the assigned labels.

The precision obtained from the test-set (about 6\% of the total of relations), was 87.01\%. Although it is not possible to state that this test-set is representative of the overall data-set, it is still strong evidence of the effectiveness of the RE corpus creation pipeline, especially between human phenotypes and genes, and other domains with a gold standard relations knowledge base. The lower recall is mostly due to incorrectly retrieved human phenotype annotations by IHP, that can be manually confirmed in a future optimized version of the PGR corpus, as some of them are parts of adjacent entities that can be combined for an accurate annotation. 

% TABLE 3.2

\begin{table}[!ht]
\renewcommand\arraystretch{1.2}
\small
\captionsetup{font=small}
\caption[Evaluation of the Silver Standard Corpus]{The number of \textit{Known} and \textit{Unknown} relations selected, the number of true positives (TP), false negatives (FN), false positives (FP) and true negatives (TN), and the evaluation metrics for the \textit{Known} relations.} 
\centering
\taburulecolor{black}
\newcolumntype{C}{ >{\centering\arraybackslash} m{1.1cm} }
\newcolumntype{D}{ >{\centering\arraybackslash} m{1cm} }
\newcolumntype{T}{ >{\centering\arraybackslash} m{1.5cm} }
\newcolumntype{E}{ >{\centering\arraybackslash} m{1.4cm} }
\newcolumntype{U}{ >{\centering\arraybackslash} m{1.8cm} }

\begin{tabular}{|E|T|D|D|D|D|T|D|U|}

\hline
\multicolumn{2}{|c|}{\textbf{Relations}} & \multicolumn{4}{c|}{\textbf{Marked Relations}} & \multicolumn{3}{c|}{\textbf{Metrics}} \\
\hline
\textbf{Known} & \textbf{Unknown} & \textbf{TP} & \textbf{FN} & \textbf{FP} & \textbf{TN} & \textbf{Precision} & \textbf{Recall} & \textbf{F-Measure}  \\
\hline\hline
77 & 143 & 67 & 86 & 10 & 57 & 0.8701 & 0.4379 & 0.5826 \\
\hline

\end{tabular}
\label{table:relations}
\end{table}

% END TABLE 3.2

The PGR corpus was made publicly available to the research community.\footnote{\url{https://github.com/lasigeBioTM/PGR}}